{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parte5-Grupo3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2kYg_Fn9apg",
        "colab_type": "code",
        "outputId": "69f84151-aedd-4ac7-f977-f51b2ee0c4c2",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 116
        }
      },
      "source": [
        "#Regressões lineares múltiplas - Método Backward\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-36901ff0-4e3f-4408-a885-f7d7a3737239\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-36901ff0-4e3f-4408-a885-f7d7a3737239\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving student-mat.csv to student-mat (5).csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'student-mat.csv': b'school,sex,age,address,famsize,Pstatus,Medu,Fedu,Mjob,Fjob,reason,guardian,traveltime,studytime,failures,schoolsup,famsup,paid,activities,nursery,higher,internet,romantic,famrel,freetime,goout,Dalc,Walc,health,absences,G1,G2,G3\\nGP,F,18,U,GT3,A,4,4,at_home,teacher,course,mother,2,2,0,yes,no,no,no,yes,yes,no,no,4,3,4,1,1,3,6,5,6,6\\nGP,F,17,U,GT3,T,1,1,at_home,other,course,father,1,2,0,no,yes,no,no,no,yes,yes,no,5,3,3,1,1,3,4,5,5,6\\nGP,F,15,U,LE3,T,1,1,at_home,other,other,mother,1,2,3,yes,no,yes,no,yes,yes,yes,no,4,3,2,2,3,3,10,7,8,10\\nGP,F,15,U,GT3,T,4,2,health,services,home,mother,1,3,0,no,yes,yes,yes,yes,yes,yes,yes,3,2,2,1,1,5,2,15,14,15\\nGP,F,16,U,GT3,T,3,3,other,other,home,father,1,2,0,no,yes,yes,no,yes,yes,no,no,4,3,2,1,2,5,4,6,10,10\\nGP,M,16,U,LE3,T,4,3,services,other,reputation,mother,1,2,0,no,yes,yes,yes,yes,yes,yes,no,5,4,2,1,2,5,10,15,15,15\\nGP,M,16,U,LE3,T,2,2,other,other,home,mother,1,2,0,no,no,no,no,yes,yes,yes,no,4,4,4,1,1,3,0,12,12,11\\nGP,F,17,U,GT3,A,4,4,other,teacher,home,mother,2,2,0,yes,yes,no,no,yes,yes,no,no,4,1,4,1,1,1,6,6,5,6\\nGP,M,15,U,LE3,A,3,2,services,other,home,mother,1,2,0,no,yes,yes,no,yes,yes,yes,no,4,2,2,1,1,1,0,16,18,19\\nGP,M,15,U,GT3,T,3,4,other,other,home,mother,1,2,0,no,yes,yes,yes,yes,yes,yes,no,5,5,1,1,1,5,0,14,15,15\\nGP,F,15,U,GT3,T,4,4,teacher,health,reputation,mother,1,2,0,no,yes,yes,no,yes,yes,yes,no,3,3,3,1,2,2,0,10,8,9\\nGP,F,15,U,GT3,T,2,1,services,other,reputation,father,3,3,0,no,yes,no,yes,yes,yes,yes,no,5,2,2,1,1,4,4,10,12,12\\nGP,M,15,U,LE3,T,4,4,health,services,course,father,1,1,0,no,yes,yes,yes,yes,yes,yes,no,4,3,3,1,3,5,2,14,14,14\\nGP,M,15,U,GT3,T,4,3,teacher,other,course,mother,2,2,0,no,yes,yes,no,yes,yes,yes,no,5,4,3,1,2,3,2,10,10,11\\nGP,M,15,U,GT3,A,2,2,other,other,home,other,1,3,0,no,yes,no,no,yes,yes,yes,yes,4,5,2,1,1,3,0,14,16,16\\nGP,F,16,U,GT3,T,4,4,health,other,home,mother,1,1,0,no,yes,no,no,yes,yes,yes,no,4,4,4,1,2,2,4,14,14,14\\nGP,F,16,U,GT3,T,4,4,services,services,reputation,mother,1,3,0,no,yes,yes,yes,yes,yes,yes,no,3,2,3,1,2,2,6,13,14,14\\nGP,F,16,U,GT3,T,3,3,other,other,reputation,mother,3,2,0,yes,yes,no,yes,yes,yes,no,no,5,3,2,1,1,4,4,8,10,10\\nGP,M,17,U,GT3,T,3,2,services,services,course,mother,1,1,3,no,yes,no,yes,yes,yes,yes,no,5,5,5,2,4,5,16,6,5,5\\nGP,M,16,U,LE3,T,4,3,health,other,home,father,1,1,0,no,no,yes,yes,yes,yes,yes,no,3,1,3,1,3,5,4,8,10,10\\nGP,M,15,U,GT3,T,4,3,teacher,other,reputation,mother,1,2,0,no,no,no,no,yes,yes,yes,no,4,4,1,1,1,1,0,13,14,15\\nGP,M,15,U,GT3,T,4,4,health,health,other,father,1,1,0,no,yes,yes,no,yes,yes,yes,no,5,4,2,1,1,5,0,12,15,15\\nGP,M,16,U,LE3,T,4,2,teacher,other,course,mother,1,2,0,no,no,no,yes,yes,yes,yes,no,4,5,1,1,3,5,2,15,15,16\\nGP,M,16,U,LE3,T,2,2,other,other,reputation,mother,2,2,0,no,yes,no,yes,yes,yes,yes,no,5,4,4,2,4,5,0,13,13,12\\nGP,F,15,R,GT3,T,2,4,services,health,course,mother,1,3,0,yes,yes,yes,yes,yes,yes,yes,no,4,3,2,1,1,5,2,10,9,8\\nGP,F,16,U,GT3,T,2,2,services,services,home,mother,1,1,2,no,yes,yes,no,no,yes,yes,no,1,2,2,1,3,5,14,6,9,8\\nGP,M,15,U,GT3,T,2,2,other,other,home,mother,1,1,0,no,yes,yes,no,yes,yes,yes,no,4,2,2,1,2,5,2,12,12,11\\nGP,M,15,U,GT3,T,4,2,health,services,other,mother,1,1,0,no,no,yes,no,yes,yes,yes,no,2,2,4,2,4,1,4,15,16,15\\nGP,M,16,U,LE3,A,3,4,services,other,home,mother,1,2,0,yes,yes,no,yes,yes,yes,yes,no,5,3,3,1,1,5,4,11,11,11\\nGP,M,16,U,GT3,T,4,4,teacher,teacher,home,mother,1,2,0,no,yes,yes,yes,yes,yes,yes,yes,4,4,5,5,5,5,16,10,12,11\\nGP,M,15,U,GT3,T,4,4,health,services,home,mother,1,2,0,no,yes,yes,no,no,yes,yes,no,5,4,2,3,4,5,0,9,11,12\\nGP,M,15,U,GT3,T,4,4,services,services,reputation,mother,2,2,0,no,yes,no,yes,yes,yes,yes,no,4,3,1,1,1,5,0,17,16,17\\nGP,M,15,R,GT3,T,4,3,teacher,at_home,course,mother,1,2,0,no,yes,no,yes,yes,yes,yes,yes,4,5,2,1,1,5,0,17,16,16\\nGP,M,15,U,LE3,T,3,3,other,other,course,mother,1,2,0,no,no,no,yes,no,yes,yes,no,5,3,2,1,1,2,0,8,10,12\\nGP,M,16,U,GT3,T,3,2,other,other,home,mother,1,1,0,no,yes,yes,no,no,yes,yes,no,5,4,3,1,1,5,0,12,14,15\\nGP,F,15,U,GT3,T,2,3,other,other,other,father,2,1,0,no,yes,no,yes,yes,yes,no,no,3,5,1,1,1,5,0,8,7,6\\nGP,M,15,U,LE3,T,4,3,teacher,services,home,mother,1,3,0,no,yes,no,yes,yes,yes,yes,no,5,4,3,1,1,4,2,15,16,18\\nGP,M,16,R,GT3,A,4,4,other,teacher,reputation,mother,2,3,0,no,yes,no,yes,yes,yes,yes,yes,2,4,3,1,1,5,7,15,16,15\\nGP,F,15,R,GT3,T,3,4,services,health,course,mother,1,3,0,yes,yes,yes,yes,yes,yes,yes,no,4,3,2,1,1,5,2,12,12,11\\nGP,F,15,R,GT3,T,2,2,at_home,other,reputation,mother,1,1,0,yes,yes,yes,yes,yes,yes,no,no,4,3,1,1,1,2,8,14,13,13\\nGP,F,16,U,LE3,T,2,2,other,other,home,mother,2,2,1,no,yes,no,yes,no,yes,yes,yes,3,3,3,1,2,3,25,7,10,11\\nGP,M,15,U,LE3,T,4,4,teacher,other,home,other,1,1,0,no,yes,no,no,no,yes,yes,yes,5,4,3,2,4,5,8,12,12,12\\nGP,M,15,U,GT3,T,4,4,services,teacher,course,father,1,2,0,no,yes,no,yes,yes,yes,yes,no,4,3,3,1,1,5,2,19,18,18\\nGP,M,15,U,GT3,T,2,2,services,services,course,father,1,1,0,yes,yes,no,no,yes,yes,yes,no,5,4,1,1,1,1,0,8,8,11\\nGP,F,16,U,LE3,T,2,2,other,at_home,course,father,2,2,1,yes,no,no,yes,yes,yes,yes,no,4,3,3,2,2,5,14,10,10,9\\nGP,F,15,U,LE3,A,4,3,other,other,course,mother,1,2,0,yes,yes,yes,yes,yes,yes,yes,yes,5,2,2,1,1,5,8,8,8,6\\nGP,F,16,U,LE3,A,3,3,other,services,home,mother,1,2,0,no,yes,no,no,yes,yes,yes,no,2,3,5,1,4,3,12,11,12,11\\nGP,M,16,U,GT3,T,4,3,health,services,reputation,mother,1,4,0,no,no,no,yes,yes,yes,yes,no,4,2,2,1,1,2,4,19,19,20\\nGP,M,15,U,GT3,T,4,2,teacher,other,home,mother,1,2,0,no,yes,yes,no,yes,yes,no,no,4,3,3,2,2,5,2,15,15,14\\nGP,F,15,U,GT3,T,4,4,services,teacher,other,father,1,2,1,yes,yes,no,yes,no,yes,yes,no,4,4,4,1,1,3,2,7,7,7\\nGP,F,16,U,LE3,T,2,2,services,services,course,mother,3,2,0,no,yes,yes,no,yes,yes,yes,no,4,3,3,2,3,4,2,12,13,13\\nGP,F,15,U,LE3,T,4,2,health,other,other,mother,1,2,0,no,yes,yes,no,yes,yes,yes,no,4,3,3,1,1,5,2,11,13,13\\nGP,M,15,U,LE3,A,4,2,health,health,other,father,2,1,1,no,no,no,no,yes,yes,no,no,5,5,5,3,4,5,6,11,11,10\\nGP,F,15,U,GT3,T,4,4,services,services,course,mother,1,1,0,yes,yes,yes,no,yes,yes,yes,no,3,3,4,2,3,5,0,8,10,11\\nGP,F,15,U,LE3,A,3,3,other,other,other,mother,1,1,0,no,no,yes,no,yes,yes,yes,no,5,3,4,4,4,1,6,10,13,13\\nGP,F,16,U,GT3,A,2,1,other,other,other,mother,1,2,0,no,no,yes,yes,yes,yes,yes,yes,5,3,4,1,1,2,8,8,9,10\\nGP,F,15,U,GT3,A,4,3,services,services,reputation,mother,1,2,0,no,yes,yes,yes,yes,yes,yes,no,4,3,2,1,1,1,0,14,15,15\\nGP,M,15,U,GT3,T,4,4,teacher,health,reputation,mother,1,2,0,no,yes,no,yes,yes,yes,no,no,3,2,2,1,1,5,4,14,15,15\\nGP,M,15,U,LE3,T,1,2,other,at_home,home,father,1,2,0,yes,yes,no,yes,yes,yes,yes,no,4,3,2,1,1,5,2,9,10,9\\nGP,F,16,U,GT3,T,4,2,services,other,course,mother,1,2,0,no,yes,no,no,yes,yes,yes,no,4,2,3,1,1,5,2,15,16,16\\nGP,F,16,R,GT3,T,4,4,health,teacher,other,mother,1,2,0,no,yes,no,yes,yes,yes,no,no,2,4,4,2,3,4,6,10,11,11\\nGP,F,16,U,GT3,T,1,1,services,services,course,father,4,1,0,yes,yes,no,yes,no,yes,yes,yes,5,5,5,5,5,5,6,10,8,11\\nGP,F,16,U,LE3,T,1,2,other,services,reputation,father,1,2,0,yes,no,no,yes,yes,yes,yes,no,4,4,3,1,1,1,4,8,10,9\\nGP,F,16,U,GT3,T,4,3,teacher,health,home,mother,1,3,0,yes,yes,yes,yes,yes,yes,yes,no,3,4,4,2,4,4,2,10,9,9\\nGP,F,15,U,LE3,T,4,3,services,services,reputation,father,1,2,0,yes,no,no,yes,yes,yes,yes,yes,4,4,4,2,4,2,0,10,10,10\\nGP,F,16,U,LE3,T,4,3,teacher,services,course,mother,3,2,0,no,yes,no,yes,yes,yes,yes,no,5,4,3,1,2,1,2,16,15,15\\nGP,M,15,U,GT3,A,4,4,other,services,reputation,mother,1,4,0,no,yes,no,yes,no,yes,yes,yes,1,3,3,5,5,3,4,13,13,12\\nGP,F,16,U,GT3,T,3,1,services,other,course,mother,1,4,0,yes,yes,yes,no,yes,yes,yes,no,4,3,3,1,2,5,4,7,7,6\\nGP,F,15,R,LE3,T,2,2,health,services,reputation,mother,2,2,0,yes,yes,yes,no,yes,yes,yes,no,4,1,3,1,3,4,2,8,9,8\\nGP,F,15,R,LE3,T,3,1,other,other,reputation,father,2,4,0,no,yes,no,no,no,yes,yes,no,4,4,2,2,3,3,12,16,16,16\\nGP,M,16,U,GT3,T,3,1,other,other,reputation,father,2,4,0,no,yes,yes,no,yes,yes,yes,no,4,3,2,1,1,5,0,13,15,15\\nGP,M,15,U,GT3,T,4,2,other,other,course,mother,1,4,0,no,no,no,no,yes,yes,yes,no,3,3,3,1,1,3,0,10,10,10\\nGP,F,15,R,GT3,T,1,1,other,other,reputation,mother,1,2,2,yes,yes,no,no,no,yes,yes,yes,3,3,4,2,4,5,2,8,6,5\\nGP,M,16,U,GT3,T,3,1,other,other,reputation,mother,1,1,0,no,no,no,yes,yes,yes,no,no,5,3,2,2,2,5,2,12,12,14\\nGP,F,16,U,GT3,T,3,3,other,services,home,mother,1,2,0,yes,yes,yes,yes,yes,yes,yes,no,4,3,3,2,4,5,54,11,12,11\\nGP,M,15,U,GT3,T,4,3,teacher,other,home,mother,1,2,0,no,yes,yes,yes,yes,yes,yes,no,4,3,3,2,3,5,6,9,9,10\\nGP,M,15,U,GT3,T,4,0,teacher,other,course,mother,2,4,0,no,no,no,yes,yes,yes,yes,no,3,4,3,1,1,1,8,11,11,10\\nGP,F,16,U,GT3,T,2,2,other,other,reputation,mother,1,4,0,no,no,yes,no,yes,yes,yes,yes,5,2,3,1,3,3,0,11,11,11\\nGP,M,17,U,GT3,T,2,1,other,other,home,mother,2,1,3,yes,yes,no,yes,yes,no,yes,no,4,5,1,1,1,3,2,8,8,10\\nGP,F,16,U,GT3,T,3,4,at_home,other,course,mother,1,2,0,no,yes,no,no,yes,yes,yes,no,2,4,3,1,2,3,12,5,5,5\\nGP,M,15,U,GT3,T,2,3,other,services,course,father,1,1,0,yes,yes,yes,yes,no,yes,yes,yes,3,2,2,1,3,3,2,10,12,12\\nGP,M,15,U,GT3,T,2,3,other,other,home,mother,1,3,0,yes,no,yes,no,no,yes,yes,no,5,3,2,1,2,5,4,11,10,11\\nGP,F,15,U,LE3,T,3,2,services,other,reputation,mother,1,2,0,no,yes,yes,no,yes,yes,yes,no,4,4,4,1,1,5,10,7,6,6\\nGP,M,15,U,LE3,T,2,2,services,services,home,mother,2,2,0,no,no,yes,yes,yes,yes,yes,no,5,3,3,1,3,4,4,15,15,15\\nGP,F,15,U,GT3,T,1,1,other,other,home,father,1,2,0,no,yes,no,yes,no,yes,yes,no,4,3,2,2,3,4,2,9,10,10\\nGP,F,15,U,GT3,T,4,4,services,services,reputation,father,2,2,2,no,no,yes,no,yes,yes,yes,yes,4,4,4,2,3,5,6,7,9,8\\nGP,F,16,U,LE3,T,2,2,at_home,other,course,mother,1,2,0,no,yes,no,no,yes,yes,no,no,4,3,4,1,2,2,4,8,7,6\\nGP,F,15,U,GT3,T,4,2,other,other,reputation,mother,1,3,0,no,yes,no,yes,yes,yes,yes,no,5,3,3,1,3,1,4,13,14,14\\nGP,M,16,U,GT3,T,2,2,services,other,reputation,father,2,2,1,no,no,yes,yes,no,yes,yes,no,4,4,2,1,1,3,12,11,10,10\\nGP,M,16,U,LE3,A,4,4,teacher,health,reputation,mother,1,2,0,no,yes,no,no,yes,yes,no,no,4,1,3,3,5,5,18,8,6,7\\nGP,F,16,U,GT3,T,3,3,other,other,home,mother,1,3,0,no,yes,yes,no,yes,yes,yes,yes,4,3,3,1,3,4,0,7,7,8\\nGP,F,15,U,GT3,T,4,3,services,other,reputation,mother,1,1,0,no,no,yes,yes,yes,yes,yes,no,4,5,5,1,3,1,4,16,17,18\\nGP,F,16,U,LE3,T,3,1,other,other,home,father,1,2,0,yes,yes,no,no,yes,yes,no,no,3,3,3,2,3,2,4,7,6,6\\nGP,F,16,U,GT3,T,4,2,teacher,services,home,mother,2,2,0,no,yes,yes,yes,yes,yes,yes,no,5,3,3,1,1,1,0,11,10,10\\nGP,M,15,U,LE3,T,2,2,services,health,reputation,mother,1,4,0,no,yes,no,yes,yes,yes,yes,no,4,3,4,1,1,4,6,11,13,14\\nGP,F,15,R,GT3,T,1,1,at_home,other,home,mother,2,4,1,yes,yes,yes,yes,yes,yes,yes,no,3,1,2,1,1,1,2,7,10,10\\nGP,M,16,R,GT3,T,4,3,services,other,reputation,mother,2,1,0,yes,yes,no,yes,no,yes,yes,no,3,3,3,1,1,4,2,11,15,15\\nGP,F,16,U,GT3,T,2,1,other,other,course,mother,1,2,0,no,yes,yes,no,yes,yes,no,yes,4,3,5,1,1,5,2,8,9,10\\nGP,F,16,U,GT3,T,4,4,other,other,reputation,mother,1,1,0,no,no,no,yes,no,yes,yes,no,5,3,4,1,2,1,6,11,14,14\\nGP,F,16,U,GT3,T,4,3,other,at_home,course,mother,1,3,0,yes,yes,yes,no,yes,yes,yes,no,5,3,5,1,1,3,0,7,9,8\\nGP,M,16,U,GT3,T,4,4,services,services,other,mother,1,1,0,yes,yes,yes,yes,yes,yes,yes,no,4,5,5,5,5,4,14,7,7,5\\nGP,M,16,U,GT3,T,4,4,services,teacher,other,father,1,3,0,no,yes,no,yes,yes,yes,yes,yes,4,4,3,1,1,4,0,16,17,17\\nGP,M,15,U,GT3,T,4,4,services,other,course,mother,1,1,0,no,yes,no,yes,no,yes,yes,no,5,3,3,1,1,5,4,10,13,14\\nGP,F,15,U,GT3,T,3,2,services,other,home,mother,2,2,0,yes,yes,yes,no,yes,yes,yes,no,4,3,5,1,1,2,26,7,6,6\\nGP,M,15,U,GT3,A,3,4,services,other,course,mother,1,2,0,no,yes,yes,yes,yes,yes,yes,no,5,4,4,1,1,1,0,16,18,18\\nGP,F,15,U,GT3,A,3,3,other,health,reputation,father,1,4,0,yes,no,no,no,yes,yes,no,no,4,3,3,1,1,4,10,10,11,11\\nGP,F,15,U,GT3,T,2,2,other,other,course,mother,1,4,0,yes,yes,yes,no,yes,yes,yes,no,5,1,2,1,1,3,8,7,8,8\\nGP,M,16,U,GT3,T,3,3,services,other,home,father,1,3,0,no,yes,no,yes,yes,yes,yes,no,5,3,3,1,1,5,2,16,18,18\\nGP,M,15,R,GT3,T,4,4,other,other,home,father,4,4,0,no,yes,yes,yes,yes,yes,yes,yes,1,3,5,3,5,1,6,10,13,13\\nGP,F,16,U,LE3,T,4,4,health,health,other,mother,1,3,0,no,yes,yes,yes,yes,yes,yes,yes,5,4,5,1,1,4,4,14,15,16\\nGP,M,15,U,LE3,A,4,4,teacher,teacher,course,mother,1,1,0,no,no,no,yes,yes,yes,yes,no,5,5,3,1,1,4,6,18,19,19\\nGP,F,16,R,GT3,T,3,3,services,other,reputation,father,1,3,1,yes,yes,no,yes,yes,yes,yes,no,4,1,2,1,1,2,0,7,10,10\\nGP,F,16,U,GT3,T,2,2,at_home,other,home,mother,1,2,1,yes,no,no,yes,yes,yes,yes,no,3,1,2,1,1,5,6,10,13,13\\nGP,M,15,U,LE3,T,4,2,teacher,other,course,mother,1,1,0,no,no,no,no,yes,yes,yes,no,3,5,2,1,1,3,10,18,19,19\\nGP,M,15,R,GT3,T,2,1,health,services,reputation,mother,1,2,0,no,no,no,yes,yes,yes,yes,yes,5,4,2,1,1,5,8,9,9,9\\nGP,M,16,U,GT3,T,4,4,teacher,teacher,course,father,1,2,0,no,yes,no,yes,yes,yes,yes,no,5,4,4,1,2,5,2,15,15,16\\nGP,M,15,U,GT3,T,4,4,other,teacher,reputation,father,2,2,0,no,yes,no,yes,yes,yes,no,no,4,4,3,1,1,2,2,11,13,14\\nGP,M,16,U,GT3,T,3,3,other,services,home,father,2,1,0,no,no,no,yes,yes,yes,yes,no,5,4,2,1,1,5,0,13,14,13\\nGP,M,17,R,GT3,T,1,3,other,other,course,father,3,2,1,no,yes,no,yes,yes,yes,yes,no,5,2,4,1,4,5,20,9,7,8\\nGP,M,15,U,GT3,T,3,4,other,other,reputation,father,1,1,0,no,no,no,no,yes,yes,yes,no,3,4,3,1,2,4,6,14,13,13\\nGP,F,15,U,GT3,T,1,2,at_home,services,course,mother,1,2,0,no,no,no,no,no,yes,yes,no,3,2,3,1,2,1,2,16,15,15\\nGP,M,15,U,GT3,T,2,2,services,services,home,father,1,4,0,no,yes,yes,yes,yes,yes,yes,no,5,5,4,1,2,5,6,16,14,15\\nGP,F,16,U,LE3,T,2,4,other,health,course,father,2,2,0,no,yes,yes,yes,yes,yes,yes,yes,4,2,2,1,2,5,2,13,13,13\\nGP,M,16,U,GT3,T,4,4,health,other,course,mother,1,1,0,no,yes,no,yes,yes,yes,yes,no,3,4,4,1,4,5,18,14,11,13\\nGP,F,16,U,GT3,T,2,2,other,other,home,mother,1,2,0,no,no,yes,no,yes,yes,yes,yes,5,4,4,1,1,5,0,8,7,8\\nGP,M,15,U,GT3,T,3,4,services,services,home,father,1,1,0,yes,no,no,no,yes,yes,yes,no,5,5,5,3,2,5,0,13,13,12\\nGP,F,15,U,LE3,A,3,4,other,other,home,mother,1,2,0,yes,no,no,yes,yes,yes,yes,yes,5,3,2,1,1,1,0,7,10,11\\nGP,F,19,U,GT3,T,0,1,at_home,other,course,other,1,2,3,no,yes,no,no,no,no,no,no,3,4,2,1,1,5,2,7,8,9\\nGP,M,18,R,GT3,T,2,2,services,other,reputation,mother,1,1,2,no,yes,no,yes,yes,yes,yes,no,3,3,3,1,2,4,0,7,4,0\\nGP,M,16,R,GT3,T,4,4,teacher,teacher,course,mother,1,1,0,no,no,yes,yes,yes,yes,yes,no,3,5,5,2,5,4,8,18,18,18\\nGP,F,15,R,GT3,T,3,4,services,teacher,course,father,2,3,2,no,yes,no,no,yes,yes,yes,yes,4,2,2,2,2,5,0,12,0,0\\nGP,F,15,U,GT3,T,1,1,at_home,other,course,mother,3,1,0,no,yes,no,yes,no,yes,yes,yes,4,3,3,1,2,4,0,8,0,0\\nGP,F,17,U,LE3,T,2,2,other,other,course,father,1,1,0,no,yes,no,no,yes,yes,yes,yes,3,4,4,1,3,5,12,10,13,12\\nGP,F,16,U,GT3,A,3,4,services,other,course,father,1,1,0,no,no,no,no,yes,yes,yes,no,3,2,1,1,4,5,16,12,11,11\\nGP,M,15,R,GT3,T,3,4,at_home,teacher,course,mother,4,2,0,no,yes,no,no,yes,yes,no,yes,5,3,3,1,1,5,0,9,0,0\\nGP,F,15,U,GT3,T,4,4,services,at_home,course,mother,1,3,0,no,yes,no,yes,yes,yes,yes,yes,4,3,3,1,1,5,0,11,0,0\\nGP,M,17,R,GT3,T,3,4,at_home,other,course,mother,3,2,0,no,no,no,no,yes,yes,no,no,5,4,5,2,4,5,0,10,0,0\\nGP,F,16,U,GT3,A,3,3,other,other,course,other,2,1,2,no,yes,no,yes,no,yes,yes,yes,4,3,2,1,1,5,0,4,0,0\\nGP,M,16,U,LE3,T,1,1,services,other,course,mother,1,2,1,no,no,no,no,yes,yes,no,yes,4,4,4,1,3,5,0,14,12,12\\nGP,F,15,U,GT3,T,4,4,teacher,teacher,course,mother,2,1,0,no,no,no,yes,yes,yes,yes,no,4,3,2,1,1,5,0,16,16,15\\nGP,M,15,U,GT3,T,4,3,teacher,services,course,father,2,4,0,yes,yes,no,no,yes,yes,yes,no,2,2,2,1,1,3,0,7,9,0\\nGP,M,16,U,LE3,T,2,2,services,services,reputation,father,2,1,2,no,yes,no,yes,yes,yes,yes,no,2,3,3,2,2,2,8,9,9,9\\nGP,F,15,U,GT3,T,4,4,teacher,services,course,mother,1,3,0,no,yes,yes,yes,yes,yes,yes,no,4,2,2,1,1,5,2,9,11,11\\nGP,F,16,U,LE3,T,1,1,at_home,at_home,course,mother,1,1,0,no,no,no,no,yes,yes,yes,no,3,4,4,3,3,1,2,14,14,13\\nGP,M,17,U,GT3,T,2,1,other,other,home,mother,1,1,3,no,yes,no,no,yes,yes,yes,no,5,4,5,1,2,5,0,5,0,0\\nGP,F,15,U,GT3,T,1,1,other,services,course,father,1,2,0,no,yes,yes,no,yes,yes,yes,no,4,4,2,1,2,5,0,8,11,11\\nGP,F,15,U,GT3,T,3,2,health,services,home,father,1,2,3,no,yes,no,no,yes,yes,yes,no,3,3,2,1,1,3,0,6,7,0\\nGP,F,15,U,GT3,T,1,2,at_home,other,course,mother,1,2,0,no,yes,yes,no,no,yes,yes,no,4,3,2,1,1,5,2,10,11,11\\nGP,M,16,U,GT3,T,4,4,teacher,teacher,course,mother,1,1,0,no,yes,no,no,yes,no,yes,yes,3,3,2,2,1,5,0,7,6,0\\nGP,M,15,U,LE3,A,2,1,services,other,course,mother,4,1,3,no,no,no,no,yes,yes,yes,no,4,5,5,2,5,5,0,8,9,10\\nGP,M,18,U,LE3,T,1,1,other,other,course,mother,1,1,3,no,no,no,no,yes,no,yes,yes,2,3,5,2,5,4,0,6,5,0\\nGP,M,16,U,LE3,T,2,1,at_home,other,course,mother,1,1,1,no,no,no,yes,yes,yes,no,yes,4,4,4,3,5,5,6,12,13,14\\nGP,F,15,R,GT3,T,3,3,services,services,reputation,other,2,3,2,no,yes,yes,yes,yes,yes,yes,yes,4,2,1,2,3,3,8,10,10,10\\nGP,M,19,U,GT3,T,3,2,services,at_home,home,mother,1,1,3,no,yes,no,no,yes,no,yes,yes,4,5,4,1,1,4,0,5,0,0\\nGP,F,17,U,GT3,T,4,4,other,teacher,course,mother,1,1,0,yes,yes,no,no,yes,yes,no,yes,4,2,1,1,1,4,0,11,11,12\\nGP,M,15,R,GT3,T,2,3,at_home,services,course,mother,1,2,0,yes,no,yes,yes,yes,yes,no,no,4,4,4,1,1,1,2,11,8,8\\nGP,M,17,R,LE3,T,1,2,other,other,reputation,mother,1,1,0,no,no,no,no,yes,yes,no,no,2,2,2,3,3,5,8,16,12,13\\nGP,F,18,R,GT3,T,1,1,at_home,other,course,mother,3,1,3,no,yes,no,yes,no,yes,no,no,5,2,5,1,5,4,6,9,8,10\\nGP,M,16,R,GT3,T,2,2,at_home,other,course,mother,3,1,0,no,no,no,no,no,yes,no,no,4,2,2,1,2,3,2,17,15,15\\nGP,M,16,U,GT3,T,3,3,other,services,course,father,1,2,1,no,yes,yes,no,yes,yes,yes,yes,4,5,5,4,4,5,4,10,12,12\\nGP,M,17,R,LE3,T,2,1,at_home,other,course,mother,2,1,2,no,no,no,yes,yes,no,yes,yes,3,3,2,2,2,5,0,7,6,0\\nGP,M,15,R,GT3,T,3,2,other,other,course,mother,2,2,2,yes,yes,no,no,yes,yes,yes,yes,4,4,4,1,4,3,6,5,9,7\\nGP,M,16,U,LE3,T,1,2,other,other,course,mother,2,1,1,no,no,no,yes,yes,yes,no,no,4,4,4,2,4,5,0,7,0,0\\nGP,M,17,U,GT3,T,1,3,at_home,services,course,father,1,1,0,no,no,no,no,yes,no,yes,no,5,3,3,1,4,2,2,10,10,10\\nGP,M,17,R,LE3,T,1,1,other,services,course,mother,4,2,3,no,no,no,yes,yes,no,no,yes,5,3,5,1,5,5,0,5,8,7\\nGP,M,16,U,GT3,T,3,2,services,services,course,mother,2,1,1,no,yes,no,yes,no,no,no,no,4,5,2,1,1,2,16,12,11,12\\nGP,M,16,U,GT3,T,2,2,other,other,course,father,1,2,0,no,no,no,no,yes,no,yes,no,4,3,5,2,4,4,4,10,10,10\\nGP,F,16,U,GT3,T,4,2,health,services,home,father,1,2,0,no,no,yes,no,yes,yes,yes,yes,4,2,3,1,1,3,0,14,15,16\\nGP,F,16,U,GT3,T,2,2,other,other,home,mother,1,2,0,no,yes,yes,no,no,yes,yes,no,5,1,5,1,1,4,0,6,7,0\\nGP,F,16,U,GT3,T,4,4,health,health,reputation,mother,1,2,0,no,yes,yes,no,yes,yes,yes,yes,4,4,2,1,1,3,0,14,14,14\\nGP,M,16,U,GT3,T,3,4,other,other,course,father,3,1,2,no,yes,no,yes,no,yes,yes,no,3,4,5,2,4,2,0,6,5,0\\nGP,M,16,U,GT3,T,1,0,other,other,reputation,mother,2,2,0,no,yes,yes,yes,yes,yes,yes,yes,4,3,2,1,1,3,2,13,15,16\\nGP,M,17,U,LE3,T,4,4,teacher,other,reputation,mother,1,2,0,no,yes,yes,yes,yes,yes,yes,no,4,4,4,1,3,5,0,13,11,10\\nGP,F,16,U,GT3,T,1,3,at_home,services,home,mother,1,2,3,no,no,no,yes,no,yes,yes,yes,4,3,5,1,1,3,0,8,7,0\\nGP,F,16,U,LE3,T,3,3,other,other,reputation,mother,2,2,0,no,yes,yes,yes,yes,yes,yes,no,4,4,5,1,1,4,4,10,11,9\\nGP,M,17,U,LE3,T,4,3,teacher,other,course,mother,2,2,0,no,no,yes,yes,yes,yes,yes,no,4,4,4,4,4,4,4,10,9,9\\nGP,F,16,U,GT3,T,2,2,services,other,reputation,mother,2,2,0,no,no,yes,yes,no,yes,yes,no,3,4,4,1,4,5,2,13,13,11\\nGP,M,17,U,GT3,T,3,3,other,other,reputation,father,1,2,0,no,no,no,yes,no,yes,yes,no,4,3,4,1,4,4,4,6,5,6\\nGP,M,16,R,GT3,T,4,2,teacher,services,other,mother,1,1,0,no,yes,no,yes,yes,yes,yes,yes,4,3,3,3,4,3,10,10,8,9\\nGP,M,17,U,GT3,T,4,3,other,other,course,mother,1,2,0,no,yes,no,yes,yes,yes,yes,yes,5,2,3,1,1,2,4,10,10,11\\nGP,M,16,U,GT3,T,4,3,teacher,other,home,mother,1,2,0,no,yes,yes,yes,yes,yes,yes,no,3,4,3,2,3,3,10,9,8,8\\nGP,M,16,U,GT3,T,3,3,services,other,home,mother,1,2,0,no,no,yes,yes,yes,yes,yes,yes,4,2,3,1,2,3,2,12,13,12\\nGP,F,17,U,GT3,T,2,4,services,services,reputation,father,1,2,0,no,yes,no,yes,yes,yes,no,no,5,4,2,2,3,5,0,16,17,17\\nGP,F,17,U,LE3,T,3,3,other,other,reputation,mother,1,2,0,no,yes,no,yes,yes,yes,yes,yes,5,3,3,2,3,1,56,9,9,8\\nGP,F,16,U,GT3,T,3,2,other,other,reputation,mother,1,2,0,no,yes,yes,no,yes,yes,yes,no,1,2,2,1,2,1,14,12,13,12\\nGP,M,17,U,GT3,T,3,3,services,services,other,mother,1,2,0,no,yes,no,yes,yes,yes,yes,yes,4,3,4,2,3,4,12,12,12,11\\nGP,M,16,U,GT3,T,1,2,services,services,other,mother,1,1,0,no,yes,yes,yes,yes,yes,yes,yes,3,3,3,1,2,3,2,11,12,11\\nGP,M,16,U,LE3,T,2,1,other,other,course,mother,1,2,0,no,no,yes,yes,yes,yes,yes,yes,4,2,3,1,2,5,0,15,15,15\\nGP,F,17,U,GT3,A,3,3,health,other,reputation,mother,1,2,0,no,yes,no,no,no,yes,yes,yes,3,3,3,1,3,3,6,8,7,9\\nGP,M,17,R,GT3,T,1,2,at_home,other,home,mother,1,2,0,no,no,no,no,yes,yes,no,no,3,1,3,1,5,3,4,8,9,10\\nGP,F,16,U,GT3,T,2,3,services,services,course,mother,1,2,0,no,no,no,no,yes,yes,yes,no,4,3,3,1,1,2,10,11,12,13\\nGP,F,17,U,GT3,T,1,1,at_home,services,course,mother,1,2,0,no,no,no,yes,yes,yes,yes,no,5,3,3,1,1,3,0,8,8,9\\nGP,M,17,U,GT3,T,1,2,at_home,services,other,other,2,2,0,no,no,yes,yes,no,yes,yes,no,4,4,4,4,5,5,12,7,8,8\\nGP,M,16,R,GT3,T,3,3,services,services,reputation,mother,1,1,0,no,yes,no,yes,yes,yes,yes,no,4,3,2,3,4,5,8,8,9,10\\nGP,M,16,U,GT3,T,2,3,other,other,home,father,2,1,0,no,no,no,no,yes,yes,yes,no,5,3,3,1,1,3,0,13,14,14\\nGP,F,17,U,LE3,T,2,4,services,services,course,father,1,2,0,no,no,no,yes,yes,yes,yes,yes,4,3,2,1,1,5,0,14,15,15\\nGP,M,17,U,GT3,T,4,4,services,teacher,home,mother,1,1,0,no,no,no,no,yes,yes,yes,no,5,2,3,1,2,5,4,17,15,16\\nGP,M,16,R,LE3,T,3,3,teacher,other,home,father,3,1,0,no,yes,yes,yes,yes,yes,yes,no,3,3,4,3,5,3,8,9,9,10\\nGP,F,17,U,GT3,T,4,4,services,teacher,home,mother,2,1,1,no,yes,no,no,yes,yes,yes,no,4,2,4,2,3,2,24,18,18,18\\nGP,F,16,U,LE3,T,4,4,teacher,teacher,reputation,mother,1,2,0,no,yes,yes,no,yes,yes,yes,no,4,5,2,1,2,3,0,9,9,10\\nGP,F,16,U,GT3,T,4,3,health,other,home,mother,1,2,0,no,yes,no,yes,yes,yes,yes,no,4,3,5,1,5,2,2,16,16,16\\nGP,F,16,U,GT3,T,2,3,other,other,reputation,mother,1,2,0,yes,yes,yes,yes,yes,yes,no,no,4,4,3,1,3,4,6,8,10,10\\nGP,F,17,U,GT3,T,1,1,other,other,course,mother,1,2,0,no,yes,yes,no,no,yes,no,no,4,4,4,1,3,1,4,9,9,10\\nGP,F,17,R,GT3,T,2,2,other,other,reputation,mother,1,1,0,no,yes,no,no,yes,yes,yes,no,5,3,2,1,2,3,18,7,6,6\\nGP,F,16,R,GT3,T,2,2,services,services,reputation,mother,2,4,0,no,yes,yes,yes,no,yes,yes,no,5,3,5,1,1,5,6,10,10,11\\nGP,F,17,U,GT3,T,3,4,at_home,services,home,mother,1,3,1,no,yes,yes,no,yes,yes,yes,yes,4,4,3,3,4,5,28,10,9,9\\nGP,F,16,U,GT3,A,3,1,services,other,course,mother,1,2,3,no,yes,yes,no,yes,yes,yes,no,2,3,3,2,2,4,5,7,7,7\\nGP,F,16,U,GT3,T,4,3,teacher,other,other,mother,1,2,0,no,no,yes,yes,yes,yes,yes,yes,1,3,2,1,1,1,10,11,12,13\\nGP,F,16,U,GT3,T,1,1,at_home,other,home,mother,2,1,0,no,yes,yes,no,yes,yes,no,no,4,3,2,1,4,5,6,9,9,10\\nGP,F,17,R,GT3,T,4,3,teacher,other,reputation,mother,2,3,0,no,yes,yes,yes,yes,yes,yes,yes,4,4,2,1,1,4,6,7,7,7\\nGP,F,19,U,GT3,T,3,3,other,other,reputation,other,1,4,0,no,yes,yes,yes,yes,yes,yes,no,4,3,3,1,2,3,10,8,8,8\\nGP,M,17,U,LE3,T,4,4,services,other,home,mother,1,2,0,no,yes,yes,no,yes,yes,yes,yes,5,3,5,4,5,3,13,12,12,13\\nGP,F,16,U,GT3,A,2,2,other,other,reputation,mother,1,2,0,yes,yes,yes,no,yes,yes,yes,no,3,3,4,1,1,4,0,12,13,14\\nGP,M,18,U,GT3,T,2,2,services,other,home,mother,1,2,1,no,yes,yes,yes,yes,yes,yes,no,4,4,4,2,4,5,15,6,7,8\\nGP,F,17,R,LE3,T,4,4,services,other,other,mother,1,1,0,no,yes,yes,no,yes,yes,no,no,5,2,1,1,2,3,12,8,10,10\\nGP,F,17,U,LE3,T,3,2,other,other,reputation,mother,2,2,0,no,no,yes,no,yes,yes,yes,no,4,4,4,1,3,1,2,14,15,15\\nGP,F,17,U,GT3,T,4,3,other,other,reputation,mother,1,2,2,no,no,yes,no,yes,yes,yes,yes,3,4,5,2,4,1,22,6,6,4\\nGP,M,18,U,LE3,T,3,3,services,health,home,father,1,2,1,no,yes,yes,no,yes,yes,yes,no,3,2,4,2,4,4,13,6,6,8\\nGP,F,17,U,GT3,T,2,3,at_home,other,home,father,2,1,0,no,yes,yes,no,yes,yes,no,no,3,3,3,1,4,3,3,7,7,8\\nGP,F,17,U,GT3,T,2,2,at_home,at_home,course,mother,1,3,0,no,yes,yes,yes,yes,yes,yes,no,4,3,3,1,1,4,4,9,10,10\\nGP,F,17,R,GT3,T,2,1,at_home,services,reputation,mother,2,2,0,no,yes,no,yes,yes,yes,yes,no,4,2,5,1,2,5,2,6,6,6\\nGP,F,17,U,GT3,T,1,1,at_home,other,reputation,mother,1,3,1,no,yes,no,yes,yes,yes,no,yes,4,3,4,1,1,5,0,6,5,0\\nGP,F,16,U,GT3,T,2,3,services,teacher,other,mother,1,2,0,yes,no,no,no,yes,yes,yes,no,2,3,1,1,1,3,2,16,16,17\\nGP,M,18,U,GT3,T,2,2,other,other,home,mother,2,2,0,no,yes,yes,no,yes,yes,yes,no,3,3,3,5,5,4,0,12,13,13\\nGP,F,16,U,GT3,T,4,4,teacher,services,home,mother,1,3,0,no,yes,no,yes,no,yes,yes,no,5,3,2,1,1,5,0,13,13,14\\nGP,F,18,R,GT3,T,3,1,other,other,reputation,mother,1,2,1,no,no,no,yes,yes,yes,yes,yes,5,3,3,1,1,4,16,9,8,7\\nGP,F,17,U,GT3,T,3,2,other,other,course,mother,1,2,0,no,no,no,yes,no,yes,yes,no,5,3,4,1,3,3,10,16,15,15\\nGP,M,17,U,LE3,T,2,3,services,services,reputation,father,1,2,0,no,yes,yes,no,no,yes,yes,no,5,3,3,1,3,3,2,12,11,12\\nGP,M,18,U,LE3,T,2,1,at_home,other,course,mother,4,2,0,yes,yes,yes,yes,yes,yes,yes,yes,4,3,2,4,5,3,14,10,8,9\\nGP,F,17,U,GT3,A,2,1,other,other,course,mother,2,3,0,no,no,no,yes,yes,yes,yes,yes,3,2,3,1,2,3,10,12,10,12\\nGP,F,17,U,LE3,T,4,3,health,other,reputation,father,1,2,0,no,no,no,yes,yes,yes,yes,yes,3,2,3,1,2,3,14,13,13,14\\nGP,M,17,R,GT3,T,2,2,other,other,course,father,2,2,0,no,yes,yes,yes,yes,yes,yes,no,4,5,2,1,1,1,4,11,11,11\\nGP,M,17,U,GT3,T,4,4,teacher,teacher,reputation,mother,1,2,0,yes,yes,no,yes,yes,yes,yes,yes,4,5,5,1,3,2,14,11,9,9\\nGP,M,16,U,GT3,T,4,4,health,other,reputation,father,1,2,0,no,yes,yes,yes,yes,yes,yes,no,4,2,4,2,4,1,2,14,13,13\\nGP,M,16,U,LE3,T,1,1,other,other,home,mother,2,2,0,no,yes,yes,no,yes,yes,yes,no,3,4,2,1,1,5,18,9,7,6\\nGP,M,16,U,GT3,T,3,2,at_home,other,reputation,mother,2,3,0,no,no,no,yes,yes,yes,yes,yes,5,3,3,1,3,2,10,11,9,10\\nGP,M,17,U,LE3,T,2,2,other,other,home,father,1,2,0,no,no,yes,yes,no,yes,yes,yes,4,4,2,5,5,4,4,14,13,13\\nGP,F,16,U,GT3,T,2,1,other,other,home,mother,1,1,0,no,no,no,no,yes,yes,yes,yes,4,5,2,1,1,5,20,13,12,12\\nGP,F,17,R,GT3,T,2,1,at_home,services,course,mother,3,2,0,no,no,no,yes,yes,yes,no,no,2,1,1,1,1,3,2,13,11,11\\nGP,M,18,U,GT3,T,2,2,other,services,reputation,father,1,2,1,no,no,no,no,yes,no,yes,no,5,5,4,3,5,2,0,7,7,0\\nGP,M,17,U,LE3,T,4,3,health,other,course,mother,2,2,0,no,no,no,yes,yes,yes,yes,yes,2,5,5,1,4,5,14,12,12,12\\nGP,M,17,R,LE3,A,4,4,teacher,other,course,mother,2,2,0,no,yes,yes,no,yes,yes,yes,no,3,3,3,2,3,4,2,10,11,12\\nGP,M,16,U,LE3,T,4,3,teacher,other,course,mother,1,1,0,no,no,no,yes,no,yes,yes,no,5,4,5,1,1,3,0,6,0,0\\nGP,M,16,U,GT3,T,4,4,services,services,course,mother,1,1,0,no,no,no,yes,yes,yes,yes,no,5,3,2,1,2,5,0,13,12,12\\nGP,F,18,U,GT3,T,2,1,other,other,course,other,2,3,0,no,yes,yes,no,no,yes,yes,yes,4,4,4,1,1,3,0,7,0,0\\nGP,M,16,U,GT3,T,2,1,other,other,course,mother,3,1,0,no,no,no,no,yes,yes,yes,no,4,3,3,1,1,4,6,18,18,18\\nGP,M,17,U,GT3,T,2,3,other,other,course,father,2,1,0,no,no,no,no,yes,yes,yes,no,5,2,2,1,1,2,4,12,12,13\\nGP,M,22,U,GT3,T,3,1,services,services,other,mother,1,1,3,no,no,no,no,no,no,yes,yes,5,4,5,5,5,1,16,6,8,8\\nGP,M,18,R,LE3,T,3,3,other,services,course,mother,1,2,1,no,yes,no,no,yes,yes,yes,yes,4,3,3,1,3,5,8,3,5,5\\nGP,M,16,U,GT3,T,0,2,other,other,other,mother,1,1,0,no,no,yes,no,no,yes,yes,no,4,3,2,2,4,5,0,13,15,15\\nGP,M,18,U,GT3,T,3,2,services,other,course,mother,2,1,1,no,no,no,no,yes,no,yes,no,4,4,5,2,4,5,0,6,8,8\\nGP,M,16,U,GT3,T,3,3,at_home,other,reputation,other,3,2,0,yes,yes,no,no,no,yes,yes,no,5,3,3,1,3,2,6,7,10,10\\nGP,M,18,U,GT3,T,2,1,services,services,other,mother,1,1,1,no,no,no,no,no,no,yes,no,3,2,5,2,5,5,4,6,9,8\\nGP,M,16,R,GT3,T,2,1,other,other,course,mother,2,1,0,no,no,no,yes,no,yes,no,no,3,3,2,1,3,3,0,8,9,8\\nGP,M,17,R,GT3,T,2,1,other,other,course,mother,1,1,0,no,no,no,no,no,yes,yes,no,4,4,2,2,4,5,0,8,12,12\\nGP,M,17,U,LE3,T,1,1,health,other,course,mother,2,1,1,no,yes,no,yes,yes,yes,yes,no,4,4,4,1,2,5,2,7,9,8\\nGP,F,17,U,LE3,T,4,2,teacher,services,reputation,mother,1,4,0,no,yes,yes,yes,yes,yes,yes,no,4,2,3,1,1,4,6,14,12,13\\nGP,M,19,U,LE3,A,4,3,services,at_home,reputation,mother,1,2,0,no,yes,no,no,yes,yes,yes,no,4,3,1,1,1,1,12,11,11,11\\nGP,M,18,U,GT3,T,2,1,other,other,home,mother,1,2,0,no,no,no,yes,yes,yes,yes,no,5,2,4,1,2,4,8,15,14,14\\nGP,F,17,U,LE3,T,2,2,services,services,course,father,1,4,0,no,no,yes,yes,yes,yes,yes,yes,3,4,1,1,1,2,0,10,9,0\\nGP,F,18,U,GT3,T,4,3,services,other,home,father,1,2,0,no,yes,yes,no,yes,yes,yes,yes,3,1,2,1,3,2,21,17,18,18\\nGP,M,18,U,GT3,T,4,3,teacher,other,course,mother,1,2,0,no,yes,yes,no,no,yes,yes,no,4,3,2,1,1,3,2,8,8,8\\nGP,M,18,R,GT3,T,3,2,other,other,course,mother,1,3,0,no,no,no,yes,no,yes,no,no,5,3,2,1,1,3,1,13,12,12\\nGP,F,17,U,GT3,T,3,3,other,other,home,mother,1,3,0,no,no,no,yes,no,yes,no,no,3,2,3,1,1,4,4,10,9,9\\nGP,F,18,U,GT3,T,2,2,at_home,services,home,mother,1,3,0,no,yes,yes,yes,yes,yes,yes,yes,4,3,3,1,1,3,0,9,10,0\\nGP,M,18,R,LE3,A,3,4,other,other,reputation,mother,2,2,0,no,yes,yes,yes,yes,yes,yes,no,4,2,5,3,4,1,13,17,17,17\\nGP,M,17,U,GT3,T,3,1,services,other,other,mother,1,2,0,no,no,yes,yes,yes,yes,yes,yes,5,4,4,3,4,5,2,9,9,10\\nGP,F,18,R,GT3,T,4,4,teacher,other,reputation,mother,2,2,0,no,no,yes,yes,yes,yes,yes,no,4,3,4,2,2,4,8,12,10,11\\nGP,M,18,U,GT3,T,4,2,health,other,reputation,father,1,2,0,no,yes,yes,yes,yes,yes,yes,yes,5,4,5,1,3,5,10,10,9,10\\nGP,F,18,R,GT3,T,2,1,other,other,reputation,mother,2,2,0,no,yes,no,no,yes,no,yes,yes,4,3,5,1,2,3,0,6,0,0\\nGP,F,19,U,GT3,T,3,3,other,services,home,other,1,2,2,no,yes,yes,yes,yes,yes,yes,no,4,3,5,3,3,5,15,9,9,9\\nGP,F,18,U,GT3,T,2,3,other,services,reputation,father,1,4,0,no,yes,yes,yes,yes,yes,yes,yes,4,5,5,1,3,2,4,15,14,14\\nGP,F,18,U,LE3,T,1,1,other,other,home,mother,2,2,0,no,yes,yes,no,no,yes,no,no,4,4,3,1,1,3,2,11,11,11\\nGP,M,17,R,GT3,T,1,2,at_home,at_home,home,mother,1,2,0,no,yes,yes,yes,no,yes,no,yes,3,5,2,2,2,1,2,15,14,14\\nGP,F,17,U,GT3,T,2,4,at_home,health,reputation,mother,2,2,0,no,yes,yes,no,yes,yes,yes,yes,4,3,3,1,1,1,2,10,10,10\\nGP,F,17,U,LE3,T,2,2,services,other,course,mother,2,2,0,yes,yes,yes,no,yes,yes,yes,yes,4,4,4,2,3,5,6,12,12,12\\nGP,F,18,R,GT3,A,3,2,other,services,home,mother,2,2,0,no,no,no,no,no,no,yes,yes,4,1,1,1,1,5,75,10,9,9\\nGP,M,18,U,GT3,T,4,4,teacher,services,home,mother,2,1,0,no,no,yes,yes,yes,yes,yes,no,3,2,4,1,4,3,22,9,9,9\\nGP,F,18,U,GT3,T,4,4,health,health,reputation,father,1,2,1,yes,yes,no,yes,yes,yes,yes,yes,2,4,4,1,1,4,15,9,8,8\\nGP,M,18,U,LE3,T,4,3,teacher,services,course,mother,2,1,0,no,no,yes,yes,yes,yes,yes,no,4,2,3,1,2,1,8,10,11,10\\nGP,M,17,U,LE3,A,4,1,services,other,home,mother,2,1,0,no,no,yes,yes,yes,yes,yes,yes,4,5,4,2,4,5,30,8,8,8\\nGP,M,17,U,LE3,A,3,2,teacher,services,home,mother,1,1,1,no,no,no,no,yes,yes,yes,no,4,4,4,3,4,3,19,11,9,10\\nGP,F,18,R,LE3,T,1,1,at_home,other,reputation,mother,2,4,0,no,yes,yes,yes,yes,yes,no,no,5,2,2,1,1,3,1,12,12,12\\nGP,F,18,U,GT3,T,1,1,other,other,home,mother,2,2,0,yes,no,no,yes,yes,yes,yes,no,5,4,4,1,1,4,4,8,9,10\\nGP,F,17,U,GT3,T,2,2,other,other,course,mother,1,2,0,no,yes,no,no,no,yes,yes,no,5,4,5,1,2,5,4,10,9,11\\nGP,M,17,U,GT3,T,1,1,other,other,reputation,father,1,2,0,no,no,yes,no,no,yes,yes,no,4,3,3,1,2,4,2,12,10,11\\nGP,F,18,U,GT3,T,2,2,at_home,at_home,other,mother,1,3,0,no,yes,yes,no,yes,yes,yes,no,4,3,3,1,2,2,5,18,18,19\\nGP,F,17,U,GT3,T,1,1,services,teacher,reputation,mother,1,3,0,no,yes,yes,no,yes,yes,yes,no,4,3,3,1,1,3,6,13,12,12\\nGP,M,18,U,GT3,T,2,1,services,services,reputation,mother,1,3,0,no,no,yes,yes,yes,yes,yes,no,4,2,4,1,3,2,6,15,14,14\\nGP,M,18,U,LE3,A,4,4,teacher,teacher,reputation,mother,1,2,0,no,yes,yes,yes,yes,yes,yes,no,5,4,3,1,1,2,9,15,13,15\\nGP,M,18,U,GT3,T,4,2,teacher,other,home,mother,1,2,0,no,yes,yes,yes,yes,yes,yes,yes,4,3,2,1,4,5,11,12,11,11\\nGP,F,17,U,GT3,T,4,3,health,services,reputation,mother,1,3,0,no,yes,yes,no,yes,yes,yes,no,4,2,2,1,2,3,0,15,15,15\\nGP,F,18,U,LE3,T,2,1,services,at_home,reputation,mother,1,2,1,no,no,no,no,yes,yes,yes,yes,5,4,3,1,1,5,12,12,12,13\\nGP,F,17,R,LE3,T,3,1,services,other,reputation,mother,2,4,0,no,yes,yes,no,yes,yes,no,no,3,1,2,1,1,3,6,18,18,18\\nGP,M,18,R,LE3,T,3,2,services,other,reputation,mother,2,3,0,no,yes,yes,yes,yes,yes,yes,no,5,4,2,1,1,4,8,14,13,14\\nGP,M,17,U,GT3,T,3,3,health,other,home,mother,1,1,0,no,yes,yes,no,yes,yes,yes,no,4,4,3,1,3,5,4,14,12,11\\nGP,F,19,U,GT3,T,4,4,health,other,reputation,other,2,2,0,no,yes,yes,yes,yes,yes,yes,no,2,3,4,2,3,2,0,10,9,0\\nGP,F,18,U,LE3,T,4,3,other,other,home,other,2,2,0,no,yes,yes,no,yes,yes,yes,yes,4,4,5,1,2,2,10,10,8,8\\nGP,F,18,U,GT3,T,4,3,other,other,reputation,father,1,4,0,no,yes,yes,no,yes,yes,yes,no,4,3,3,1,1,3,0,14,13,14\\nGP,M,18,U,LE3,T,4,4,teacher,teacher,home,mother,1,1,0,no,yes,yes,no,yes,yes,yes,yes,1,4,2,2,2,1,5,16,15,16\\nGP,F,18,U,LE3,A,4,4,health,other,home,mother,1,2,0,no,yes,no,no,yes,yes,yes,yes,4,2,4,1,1,4,14,12,10,11\\nGP,M,17,U,LE3,T,4,4,other,teacher,home,father,2,1,0,no,no,yes,no,yes,yes,yes,no,4,1,1,2,2,5,0,11,11,10\\nGP,F,17,U,GT3,T,4,2,other,other,reputation,mother,2,3,0,no,yes,yes,no,yes,yes,yes,no,4,3,3,1,1,3,0,15,12,14\\nGP,F,17,U,GT3,T,3,2,health,health,reputation,father,1,4,0,no,yes,yes,yes,no,yes,yes,no,5,2,2,1,2,5,0,17,17,18\\nGP,M,19,U,GT3,T,3,3,other,other,home,other,1,2,1,no,yes,no,yes,yes,yes,yes,yes,4,4,4,1,1,3,20,15,14,13\\nGP,F,18,U,GT3,T,2,4,services,at_home,reputation,other,1,2,1,no,yes,yes,yes,yes,yes,yes,no,4,4,3,1,1,3,8,14,12,12\\nGP,M,20,U,GT3,A,3,2,services,other,course,other,1,1,0,no,no,no,yes,yes,yes,no,no,5,5,3,1,1,5,0,17,18,18\\nGP,M,19,U,GT3,T,4,4,teacher,services,reputation,other,2,1,1,no,yes,yes,no,yes,yes,yes,yes,4,3,4,1,1,4,38,8,9,8\\nGP,M,19,R,GT3,T,3,3,other,services,reputation,father,1,2,1,no,no,no,yes,yes,yes,no,yes,4,5,3,1,2,5,0,15,12,12\\nGP,F,19,U,LE3,T,1,1,at_home,other,reputation,other,1,2,1,yes,yes,no,yes,no,yes,yes,no,4,4,3,1,3,3,18,12,10,10\\nGP,F,19,U,LE3,T,1,2,services,services,home,other,1,2,1,no,no,no,yes,no,yes,no,yes,4,2,4,2,2,3,0,9,9,0\\nGP,F,19,U,GT3,T,2,1,at_home,other,other,other,3,2,0,no,yes,no,no,yes,no,yes,yes,3,4,1,1,1,2,20,14,12,13\\nGP,M,19,U,GT3,T,1,2,other,services,course,other,1,2,1,no,no,no,no,no,yes,yes,no,4,5,2,2,2,4,3,13,11,11\\nGP,F,19,U,LE3,T,3,2,services,other,reputation,other,2,2,1,no,yes,yes,no,no,yes,yes,yes,4,2,2,1,2,1,22,13,10,11\\nGP,F,19,U,GT3,T,1,1,at_home,health,home,other,1,3,2,no,no,no,no,no,yes,yes,yes,4,1,2,1,1,3,14,15,13,13\\nGP,F,19,R,GT3,T,2,3,other,other,reputation,other,1,3,1,no,no,no,no,yes,yes,yes,yes,4,1,2,1,1,3,40,13,11,11\\nGP,F,18,U,GT3,T,2,1,services,other,course,mother,2,2,0,no,yes,yes,yes,yes,yes,yes,no,5,3,3,1,2,1,0,8,8,0\\nGP,F,18,U,GT3,T,4,3,other,other,course,mother,1,3,0,no,yes,yes,yes,yes,yes,yes,yes,4,3,4,1,1,5,9,9,10,9\\nGP,F,17,R,GT3,T,3,4,at_home,services,course,father,1,3,0,no,yes,yes,yes,no,yes,yes,no,4,3,4,2,5,5,0,11,11,10\\nGP,F,18,U,GT3,T,4,4,teacher,other,course,mother,1,2,0,no,yes,yes,no,yes,yes,yes,no,4,4,4,3,3,5,2,11,11,11\\nGP,F,17,U,GT3,A,4,3,services,services,course,mother,1,2,0,no,yes,yes,no,yes,yes,yes,yes,5,2,2,1,2,5,23,13,13,13\\nGP,F,17,U,GT3,T,2,2,other,other,course,mother,1,2,0,no,yes,no,no,yes,yes,no,yes,4,2,2,1,1,3,12,11,9,9\\nGP,F,17,R,LE3,T,2,2,services,services,course,mother,1,3,0,no,yes,yes,yes,yes,yes,yes,no,3,3,2,2,2,3,3,11,11,11\\nGP,F,17,U,GT3,T,3,1,services,services,course,father,1,3,0,no,yes,no,no,no,yes,yes,no,3,4,3,2,3,5,1,12,14,15\\nGP,F,17,U,LE3,T,0,2,at_home,at_home,home,father,2,3,0,no,no,no,no,yes,yes,yes,no,3,3,3,2,3,2,0,16,15,15\\nGP,M,18,U,GT3,T,4,4,other,other,course,mother,1,3,0,no,no,no,yes,yes,yes,yes,no,4,3,3,2,2,3,3,9,12,11\\nGP,M,17,U,GT3,T,3,3,other,services,reputation,mother,1,1,0,no,no,no,yes,no,yes,yes,no,4,3,5,3,5,5,3,14,15,16\\nGP,M,17,R,GT3,T,2,2,services,other,course,mother,4,1,0,no,yes,no,no,yes,yes,yes,no,4,4,5,5,5,4,8,11,10,10\\nGP,F,17,U,GT3,T,4,4,teacher,services,course,mother,1,3,0,no,yes,yes,yes,yes,yes,yes,no,5,4,4,1,3,4,7,10,9,9\\nGP,F,17,U,GT3,T,4,4,teacher,teacher,course,mother,2,3,0,no,yes,yes,no,no,yes,yes,yes,4,3,3,1,2,4,4,14,14,14\\nGP,M,18,U,LE3,T,2,2,other,other,course,mother,1,4,0,no,yes,no,yes,yes,yes,yes,no,4,5,5,2,4,5,2,9,8,8\\nGP,F,17,R,GT3,T,2,4,at_home,other,course,father,1,3,0,no,yes,no,no,yes,yes,yes,yes,4,4,3,1,1,5,7,12,14,14\\nGP,F,18,U,GT3,T,3,3,services,services,home,mother,1,2,0,no,no,no,yes,yes,yes,yes,no,5,3,4,1,1,4,0,7,0,0\\nGP,F,18,U,LE3,T,2,2,other,other,home,other,1,2,0,no,no,no,yes,no,yes,yes,yes,4,3,3,1,1,2,0,8,8,0\\nGP,F,18,R,GT3,T,2,2,at_home,other,course,mother,2,4,0,no,no,no,yes,yes,yes,no,no,4,4,4,1,1,4,0,10,9,0\\nGP,F,17,U,GT3,T,3,4,services,other,course,mother,1,3,0,no,no,no,no,yes,yes,yes,no,4,4,5,1,3,5,16,16,15,15\\nGP,F,19,R,GT3,A,3,1,services,at_home,home,other,1,3,1,no,no,yes,no,yes,yes,no,no,5,4,3,1,2,5,12,14,13,13\\nGP,F,17,U,GT3,T,3,2,other,other,home,mother,1,2,0,no,yes,yes,no,yes,yes,yes,yes,4,3,2,2,3,2,0,7,8,0\\nGP,F,18,U,LE3,T,3,3,services,services,home,mother,1,4,0,no,yes,no,no,yes,yes,yes,no,5,3,3,1,1,1,7,16,15,17\\nGP,F,17,R,GT3,A,3,2,other,other,home,mother,1,2,0,no,yes,yes,no,yes,yes,yes,no,4,3,3,2,3,2,4,9,10,10\\nGP,F,19,U,GT3,T,2,1,services,services,home,other,1,3,1,no,no,yes,yes,yes,yes,yes,yes,4,3,4,1,3,3,4,11,12,11\\nGP,M,18,U,GT3,T,4,4,teacher,services,home,father,1,2,1,no,yes,no,yes,yes,yes,yes,no,4,3,3,2,2,2,0,10,10,0\\nGP,M,18,U,LE3,T,3,4,services,other,home,mother,1,2,0,no,no,no,yes,yes,yes,yes,yes,4,3,3,1,3,5,11,16,15,15\\nGP,F,17,U,GT3,A,2,2,at_home,at_home,home,father,1,2,1,no,yes,no,no,yes,yes,yes,yes,3,3,1,1,2,4,0,9,8,0\\nGP,F,18,U,GT3,T,2,3,at_home,other,course,mother,1,3,0,no,yes,no,no,yes,yes,yes,no,4,3,3,1,2,3,4,11,10,10\\nGP,F,18,U,GT3,T,3,2,other,services,other,mother,1,3,0,no,no,no,no,yes,yes,yes,yes,5,4,3,2,3,1,7,13,13,14\\nGP,M,18,R,GT3,T,4,3,teacher,services,course,mother,1,3,0,no,no,no,no,yes,yes,yes,yes,5,3,2,1,2,4,9,16,15,16\\nGP,M,18,U,GT3,T,4,3,teacher,other,course,mother,1,3,0,no,yes,yes,no,yes,yes,yes,yes,5,4,5,2,3,5,0,10,10,9\\nGP,F,17,U,GT3,T,4,3,health,other,reputation,mother,1,3,0,no,yes,yes,yes,yes,yes,yes,yes,4,4,3,1,3,4,0,13,15,15\\nMS,M,18,R,GT3,T,3,2,other,other,course,mother,2,1,1,no,yes,no,no,no,yes,yes,no,2,5,5,5,5,5,10,11,13,13\\nMS,M,19,R,GT3,T,1,1,other,services,home,other,3,2,3,no,no,no,no,yes,yes,yes,no,5,4,4,3,3,2,8,8,7,8\\nMS,M,17,U,GT3,T,3,3,health,other,course,mother,2,2,0,no,yes,yes,no,yes,yes,yes,no,4,5,4,2,3,3,2,13,13,13\\nMS,M,18,U,LE3,T,1,3,at_home,services,course,mother,1,1,1,no,no,no,no,yes,no,yes,yes,4,3,3,2,3,3,7,8,7,8\\nMS,M,19,R,GT3,T,1,1,other,other,home,other,3,1,1,no,yes,no,no,yes,yes,yes,no,4,4,4,3,3,5,4,8,8,8\\nMS,M,17,R,GT3,T,4,3,services,other,home,mother,2,2,0,no,yes,yes,yes,no,yes,yes,yes,4,5,5,1,3,2,4,13,11,11\\nMS,F,18,U,GT3,T,3,3,services,services,course,father,1,2,0,no,yes,no,no,yes,yes,no,yes,5,3,4,1,1,5,0,10,9,9\\nMS,F,17,R,GT3,T,4,4,teacher,services,other,father,2,2,0,no,yes,yes,yes,yes,yes,yes,no,4,3,3,1,2,5,4,12,13,13\\nMS,F,17,U,LE3,A,3,2,services,other,reputation,mother,2,2,0,no,no,no,no,yes,yes,no,yes,1,2,3,1,2,5,2,12,12,11\\nMS,M,18,U,LE3,T,1,1,other,services,home,father,2,1,0,no,no,no,no,no,yes,yes,yes,3,3,2,1,2,3,4,10,10,10\\nMS,F,18,U,LE3,T,1,1,at_home,services,course,father,2,3,0,no,no,no,no,yes,yes,yes,no,5,3,2,1,1,4,0,18,16,16\\nMS,F,18,R,LE3,A,1,4,at_home,other,course,mother,3,2,0,no,no,no,no,yes,yes,no,yes,4,3,4,1,4,5,0,13,13,13\\nMS,M,18,R,LE3,T,1,1,at_home,other,other,mother,2,2,1,no,no,no,yes,no,no,no,no,4,4,3,2,3,5,2,13,12,12\\nMS,F,18,U,GT3,T,3,3,services,services,other,mother,2,2,0,no,yes,no,no,yes,yes,yes,yes,4,3,2,1,3,3,0,11,11,10\\nMS,F,17,U,LE3,T,4,4,at_home,at_home,course,mother,1,2,0,no,yes,yes,yes,yes,yes,yes,yes,2,3,4,1,1,1,0,16,15,15\\nMS,F,17,R,GT3,T,1,2,other,services,course,father,2,2,0,no,no,no,no,no,yes,no,no,3,2,2,1,2,3,0,12,11,12\\nMS,M,18,R,GT3,T,1,3,at_home,other,course,mother,2,2,0,no,yes,yes,no,yes,yes,no,no,3,3,4,2,4,3,4,10,10,10\\nMS,M,18,U,LE3,T,4,4,teacher,services,other,mother,2,3,0,no,no,yes,no,yes,yes,yes,yes,4,2,2,2,2,5,0,13,13,13\\nMS,F,17,R,GT3,T,1,1,other,services,reputation,mother,3,1,1,no,yes,yes,no,yes,yes,yes,yes,5,2,1,1,2,1,0,7,6,0\\nMS,F,18,U,GT3,T,2,3,at_home,services,course,father,2,1,0,no,yes,yes,no,yes,yes,yes,yes,5,2,3,1,2,4,0,11,10,10\\nMS,F,18,R,GT3,T,4,4,other,teacher,other,father,3,2,0,no,yes,yes,no,no,yes,yes,yes,3,2,2,4,2,5,10,14,12,11\\nMS,F,19,U,LE3,T,3,2,services,services,home,other,2,2,2,no,no,no,yes,yes,yes,no,yes,3,2,2,1,1,3,4,7,7,9\\nMS,M,18,R,LE3,T,1,2,at_home,services,other,father,3,1,0,no,yes,yes,yes,yes,no,yes,yes,4,3,3,2,3,3,3,14,12,12\\nMS,F,17,U,GT3,T,2,2,other,at_home,home,mother,1,3,0,no,no,no,yes,yes,yes,no,yes,3,4,3,1,1,3,8,13,11,11\\nMS,F,17,R,GT3,T,1,2,other,other,course,mother,1,1,0,no,no,no,yes,yes,yes,yes,no,3,5,5,1,3,1,14,6,5,5\\nMS,F,18,R,LE3,T,4,4,other,other,reputation,mother,2,3,0,no,no,no,no,yes,yes,yes,no,5,4,4,1,1,1,0,19,18,19\\nMS,F,18,R,GT3,T,1,1,other,other,home,mother,4,3,0,no,no,no,no,yes,yes,yes,no,4,3,2,1,2,4,2,8,8,10\\nMS,F,20,U,GT3,T,4,2,health,other,course,other,2,3,2,no,yes,yes,no,no,yes,yes,yes,5,4,3,1,1,3,4,15,14,15\\nMS,F,18,R,LE3,T,4,4,teacher,services,course,mother,1,2,0,no,no,yes,yes,yes,yes,yes,no,5,4,3,3,4,2,4,8,9,10\\nMS,F,18,U,GT3,T,3,3,other,other,home,mother,1,2,0,no,no,yes,no,yes,yes,yes,yes,4,1,3,1,2,1,0,15,15,15\\nMS,F,17,R,GT3,T,3,1,at_home,other,reputation,mother,1,2,0,no,yes,yes,yes,no,yes,yes,no,4,5,4,2,3,1,17,10,10,10\\nMS,M,18,U,GT3,T,4,4,teacher,teacher,home,father,1,2,0,no,no,yes,yes,no,yes,yes,no,3,2,4,1,4,2,4,15,14,14\\nMS,M,18,R,GT3,T,2,1,other,other,other,mother,2,1,0,no,no,no,yes,no,yes,yes,yes,4,4,3,1,3,5,5,7,6,7\\nMS,M,17,U,GT3,T,2,3,other,services,home,father,2,2,0,no,no,no,yes,yes,yes,yes,no,4,4,3,1,1,3,2,11,11,10\\nMS,M,19,R,GT3,T,1,1,other,services,other,mother,2,1,1,no,no,no,no,yes,yes,no,no,4,3,2,1,3,5,0,6,5,0\\nMS,M,18,R,GT3,T,4,2,other,other,home,father,2,1,1,no,no,yes,no,yes,yes,no,no,5,4,3,4,3,3,14,6,5,5\\nMS,F,18,R,GT3,T,2,2,at_home,other,other,mother,2,3,0,no,no,yes,no,yes,yes,no,no,5,3,3,1,3,4,2,10,9,10\\nMS,F,18,R,GT3,T,4,4,teacher,at_home,reputation,mother,3,1,0,no,yes,yes,yes,yes,yes,yes,yes,4,4,3,2,2,5,7,6,5,6\\nMS,F,19,R,GT3,T,2,3,services,other,course,mother,1,3,1,no,no,no,yes,no,yes,yes,no,5,4,2,1,2,5,0,7,5,0\\nMS,F,18,U,LE3,T,3,1,teacher,services,course,mother,1,2,0,no,yes,yes,no,yes,yes,yes,no,4,3,4,1,1,1,0,7,9,8\\nMS,F,18,U,GT3,T,1,1,other,other,course,mother,2,2,1,no,no,no,yes,yes,yes,no,no,1,1,1,1,1,5,0,6,5,0\\nMS,M,20,U,LE3,A,2,2,services,services,course,other,1,2,2,no,yes,yes,no,yes,yes,no,no,5,5,4,4,5,4,11,9,9,9\\nMS,M,17,U,LE3,T,3,1,services,services,course,mother,2,1,0,no,no,no,no,no,yes,yes,no,2,4,5,3,4,2,3,14,16,16\\nMS,M,21,R,GT3,T,1,1,other,other,course,other,1,1,3,no,no,no,no,no,yes,no,no,5,5,3,3,3,3,3,10,8,7\\nMS,M,18,R,LE3,T,3,2,services,other,course,mother,3,1,0,no,no,no,no,no,yes,yes,no,4,4,1,3,4,5,0,11,12,10\\nMS,M,19,U,LE3,T,1,1,other,at_home,course,father,1,1,0,no,no,no,no,yes,yes,yes,no,3,2,3,3,3,5,5,8,9,9\\n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpyAd-_n9zSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd                             \n",
        "import statsmodels.api as sm                       \n",
        "import matplotlib.pyplot as plt   \n",
        "\n",
        "\n",
        "df=pd.read_csv('student-mat.csv')\n",
        "df=df[df.G3 != 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWwGa6BEzTR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Regressão linear múltipla sem a presença das variáveis explicativas (G1,G2)\n",
        "\n",
        "df1 = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "dummy=pd.get_dummies(df1['Medu'],drop_first=True)\n",
        "dummy.columns=['Medu1','Medu2','Medu3','Medu4']\n",
        "\n",
        "dummy2=pd.get_dummies(df1['traveltime'],drop_first=True)\n",
        "dummy2.columns=['traveltime2','traveltime3','traveltime4']\n",
        "\n",
        "dummy3=pd.get_dummies(df1['studytime'],drop_first=True)\n",
        "dummy3.columns=['studytime2','studytime3','studytime4']\n",
        "\n",
        "dummy4=pd.get_dummies(df1['freetime'],drop_first=True)\n",
        "dummy4.columns=['freetime2','freetime3','freetime4','freetime5']\n",
        "\n",
        "dummy5=pd.get_dummies(df1['goout'],drop_first=True)\n",
        "dummy5.columns=['goout2','goout3','goout4','goout5']\n",
        "\n",
        "dummy6=pd.get_dummies(df1['Dalc'],drop_first=True)\n",
        "dummy6.columns=['Dalc2','Dalc3','Dalc4','Dalc5']\n",
        "\n",
        "dummy7=pd.get_dummies(df1['Walc'],drop_first=True)\n",
        "dummy7.columns=['Walc2','Walc3','Walc4','Walc5']\n",
        "\n",
        "dummy8=pd.get_dummies(df1['Fedu'],drop_first=True)\n",
        "dummy8.columns=['Fedu1','Fedu2','Fedu3','Fedu4']\n",
        "\n",
        "dummy9=pd.get_dummies(df1['famrel'],drop_first=True)\n",
        "dummy9.columns=['famrel2','famrel3','famrel4','famrel5']\n",
        "\n",
        "\n",
        "dummy10=pd.get_dummies(df1['health'],drop_first=True)\n",
        "dummy10.columns=['health2','health3','health4','health5']\n",
        "\n",
        "\n",
        "\n",
        "df4=pd.concat([df1,dummy,dummy2,dummy3,dummy4,dummy5,dummy6,dummy7,dummy8,dummy9,dummy10], axis=1)\n",
        "\n",
        "df4 = df4.drop(['Medu','traveltime','studytime','freetime','goout','Dalc','Walc','Fedu','famrel','health','G1','G2'], axis=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4vjRXl90O94",
        "colab_type": "code",
        "outputId": "b178d299-49ff-4f33-e401-ca55d887e121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1919
        }
      },
      "source": [
        "x = df4.drop(\"G3\",axis=1)\n",
        "y = df4[\"G3\"]\n",
        "X1=sm.add_constant(x)                                                \n",
        "model = sm.OLS(y,X1).fit()          \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
            "  return ptp(axis=axis, out=out, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>           <td>G3</td>        <th>  R-squared:         </th> <td>   0.394</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.253</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.803</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 11 May 2019</td> <th>  Prob (F-statistic):</th> <td>1.42e-09</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>16:54:25</td>     <th>  Log-Likelihood:    </th> <td> -835.03</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   357</td>      <th>  AIC:               </th> <td>   1806.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   289</td>      <th>  BIC:               </th> <td>   2070.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    67</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>             <td>   16.3146</td> <td>    4.487</td> <td>    3.636</td> <td> 0.000</td> <td>    7.484</td> <td>   25.145</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>age</th>               <td>   -0.1354</td> <td>    0.164</td> <td>   -0.825</td> <td> 0.410</td> <td>   -0.458</td> <td>    0.188</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>failures</th>          <td>   -1.0340</td> <td>    0.281</td> <td>   -3.675</td> <td> 0.000</td> <td>   -1.588</td> <td>   -0.480</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>absences</th>          <td>   -0.0550</td> <td>    0.022</td> <td>   -2.540</td> <td> 0.012</td> <td>   -0.098</td> <td>   -0.012</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>school_MS</th>         <td>   -0.4731</td> <td>    0.597</td> <td>   -0.792</td> <td> 0.429</td> <td>   -1.649</td> <td>    0.703</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>sex_M</th>             <td>    0.5044</td> <td>    0.375</td> <td>    1.345</td> <td> 0.180</td> <td>   -0.234</td> <td>    1.243</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>address_U</th>         <td>    0.4939</td> <td>    0.442</td> <td>    1.116</td> <td> 0.265</td> <td>   -0.377</td> <td>    1.365</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>famsize_LE3</th>       <td>    0.4288</td> <td>    0.365</td> <td>    1.175</td> <td> 0.241</td> <td>   -0.290</td> <td>    1.147</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Pstatus_T</th>         <td>   -0.0399</td> <td>    0.545</td> <td>   -0.073</td> <td> 0.942</td> <td>   -1.112</td> <td>    1.032</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Mjob_health</th>       <td>    1.0660</td> <td>    0.851</td> <td>    1.252</td> <td> 0.212</td> <td>   -0.610</td> <td>    2.742</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Mjob_other</th>        <td>   -0.4245</td> <td>    0.558</td> <td>   -0.761</td> <td> 0.447</td> <td>   -1.523</td> <td>    0.674</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Mjob_services</th>     <td>    0.7885</td> <td>    0.625</td> <td>    1.262</td> <td> 0.208</td> <td>   -0.442</td> <td>    2.019</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Mjob_teacher</th>      <td>   -0.6375</td> <td>    0.800</td> <td>   -0.796</td> <td> 0.426</td> <td>   -2.213</td> <td>    0.938</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fjob_health</th>       <td>   -0.7941</td> <td>    1.067</td> <td>   -0.744</td> <td> 0.457</td> <td>   -2.894</td> <td>    1.306</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fjob_other</th>        <td>   -0.3607</td> <td>    0.786</td> <td>   -0.459</td> <td> 0.647</td> <td>   -1.909</td> <td>    1.187</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fjob_services</th>     <td>   -0.5434</td> <td>    0.812</td> <td>   -0.669</td> <td> 0.504</td> <td>   -2.141</td> <td>    1.055</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fjob_teacher</th>      <td>    1.2324</td> <td>    1.019</td> <td>    1.209</td> <td> 0.228</td> <td>   -0.774</td> <td>    3.238</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>reason_home</th>       <td>    0.4104</td> <td>    0.421</td> <td>    0.974</td> <td> 0.331</td> <td>   -0.419</td> <td>    1.240</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>reason_other</th>      <td>   -0.0229</td> <td>    0.591</td> <td>   -0.039</td> <td> 0.969</td> <td>   -1.186</td> <td>    1.141</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>reason_reputation</th> <td>    0.2547</td> <td>    0.432</td> <td>    0.590</td> <td> 0.555</td> <td>   -0.595</td> <td>    1.104</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>guardian_mother</th>   <td>   -0.0041</td> <td>    0.401</td> <td>   -0.010</td> <td> 0.992</td> <td>   -0.793</td> <td>    0.785</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>guardian_other</th>    <td>    0.6634</td> <td>    0.773</td> <td>    0.858</td> <td> 0.392</td> <td>   -0.859</td> <td>    2.186</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>schoolsup_yes</th>     <td>   -2.1368</td> <td>    0.488</td> <td>   -4.382</td> <td> 0.000</td> <td>   -3.097</td> <td>   -1.177</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>famsup_yes</th>        <td>   -0.7020</td> <td>    0.353</td> <td>   -1.990</td> <td> 0.048</td> <td>   -1.396</td> <td>   -0.008</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>paid_yes</th>          <td>   -0.2848</td> <td>    0.359</td> <td>   -0.794</td> <td> 0.428</td> <td>   -0.991</td> <td>    0.421</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>activities_yes</th>    <td>   -0.0669</td> <td>    0.339</td> <td>   -0.198</td> <td> 0.844</td> <td>   -0.734</td> <td>    0.600</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>nursery_yes</th>       <td>   -0.2617</td> <td>    0.420</td> <td>   -0.623</td> <td> 0.534</td> <td>   -1.089</td> <td>    0.565</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>higher_yes</th>        <td>    0.0758</td> <td>    0.934</td> <td>    0.081</td> <td> 0.935</td> <td>   -1.763</td> <td>    1.914</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>internet_yes</th>      <td>    0.6104</td> <td>    0.461</td> <td>    1.325</td> <td> 0.186</td> <td>   -0.296</td> <td>    1.517</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>romantic_yes</th>      <td>   -0.0120</td> <td>    0.365</td> <td>   -0.033</td> <td> 0.974</td> <td>   -0.730</td> <td>    0.706</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Medu1</th>             <td>   -1.8515</td> <td>    1.795</td> <td>   -1.031</td> <td> 0.303</td> <td>   -5.385</td> <td>    1.682</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Medu2</th>             <td>   -1.5399</td> <td>    1.800</td> <td>   -0.856</td> <td> 0.393</td> <td>   -5.082</td> <td>    2.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Medu3</th>             <td>   -1.3645</td> <td>    1.822</td> <td>   -0.749</td> <td> 0.455</td> <td>   -4.951</td> <td>    2.222</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Medu4</th>             <td>   -1.2090</td> <td>    1.870</td> <td>   -0.646</td> <td> 0.518</td> <td>   -4.890</td> <td>    2.472</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>traveltime2</th>       <td>   -0.1872</td> <td>    0.383</td> <td>   -0.489</td> <td> 0.625</td> <td>   -0.941</td> <td>    0.566</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>traveltime3</th>       <td>    0.7669</td> <td>    0.760</td> <td>    1.009</td> <td> 0.314</td> <td>   -0.730</td> <td>    2.264</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>traveltime4</th>       <td>   -0.3450</td> <td>    1.301</td> <td>   -0.265</td> <td> 0.791</td> <td>   -2.906</td> <td>    2.216</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>studytime2</th>        <td>   -0.0317</td> <td>    0.417</td> <td>   -0.076</td> <td> 0.939</td> <td>   -0.853</td> <td>    0.790</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>studytime3</th>        <td>    1.1585</td> <td>    0.576</td> <td>    2.011</td> <td> 0.045</td> <td>    0.025</td> <td>    2.292</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>studytime4</th>        <td>    1.3758</td> <td>    0.752</td> <td>    1.830</td> <td> 0.068</td> <td>   -0.104</td> <td>    2.855</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>freetime2</th>         <td>    0.7389</td> <td>    0.857</td> <td>    0.862</td> <td> 0.389</td> <td>   -0.948</td> <td>    2.426</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>freetime3</th>         <td>    0.1529</td> <td>    0.826</td> <td>    0.185</td> <td> 0.853</td> <td>   -1.473</td> <td>    1.779</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>freetime4</th>         <td>    0.1800</td> <td>    0.855</td> <td>    0.211</td> <td> 0.833</td> <td>   -1.503</td> <td>    1.863</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>freetime5</th>         <td>    1.2792</td> <td>    0.968</td> <td>    1.322</td> <td> 0.187</td> <td>   -0.625</td> <td>    3.184</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>goout2</th>            <td>    0.4406</td> <td>    0.773</td> <td>    0.570</td> <td> 0.569</td> <td>   -1.081</td> <td>    1.962</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>goout3</th>            <td>   -0.3843</td> <td>    0.772</td> <td>   -0.498</td> <td> 0.619</td> <td>   -1.903</td> <td>    1.134</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>goout4</th>            <td>   -0.8504</td> <td>    0.813</td> <td>   -1.046</td> <td> 0.297</td> <td>   -2.451</td> <td>    0.750</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>goout5</th>            <td>   -1.2672</td> <td>    0.882</td> <td>   -1.436</td> <td> 0.152</td> <td>   -3.004</td> <td>    0.469</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Dalc2</th>             <td>   -0.1075</td> <td>    0.494</td> <td>   -0.217</td> <td> 0.828</td> <td>   -1.080</td> <td>    0.865</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Dalc3</th>             <td>    0.0492</td> <td>    0.763</td> <td>    0.065</td> <td> 0.949</td> <td>   -1.452</td> <td>    1.551</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Dalc4</th>             <td>   -0.9420</td> <td>    1.150</td> <td>   -0.819</td> <td> 0.413</td> <td>   -3.206</td> <td>    1.322</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Dalc5</th>             <td>   -0.9964</td> <td>    1.348</td> <td>   -0.739</td> <td> 0.460</td> <td>   -3.649</td> <td>    1.656</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Walc2</th>             <td>   -0.5637</td> <td>    0.466</td> <td>   -1.210</td> <td> 0.227</td> <td>   -1.480</td> <td>    0.353</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Walc3</th>             <td>   -0.2894</td> <td>    0.509</td> <td>   -0.569</td> <td> 0.570</td> <td>   -1.291</td> <td>    0.712</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Walc4</th>             <td>   -0.9857</td> <td>    0.654</td> <td>   -1.506</td> <td> 0.133</td> <td>   -2.274</td> <td>    0.302</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Walc5</th>             <td>    0.7030</td> <td>    1.040</td> <td>    0.676</td> <td> 0.500</td> <td>   -1.345</td> <td>    2.751</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fedu1</th>             <td>   -0.5798</td> <td>    2.143</td> <td>   -0.271</td> <td> 0.787</td> <td>   -4.798</td> <td>    3.638</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fedu2</th>             <td>   -0.2362</td> <td>    2.142</td> <td>   -0.110</td> <td> 0.912</td> <td>   -4.452</td> <td>    3.980</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fedu3</th>             <td>   -0.4048</td> <td>    2.149</td> <td>   -0.188</td> <td> 0.851</td> <td>   -4.634</td> <td>    3.824</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fedu4</th>             <td>    0.1427</td> <td>    2.185</td> <td>    0.065</td> <td> 0.948</td> <td>   -4.158</td> <td>    4.443</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>famrel2</th>           <td>    1.4468</td> <td>    1.427</td> <td>    1.014</td> <td> 0.312</td> <td>   -1.362</td> <td>    4.256</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>famrel3</th>           <td>    0.5621</td> <td>    1.233</td> <td>    0.456</td> <td> 0.649</td> <td>   -1.865</td> <td>    2.989</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>famrel4</th>           <td>    0.6923</td> <td>    1.193</td> <td>    0.581</td> <td> 0.562</td> <td>   -1.655</td> <td>    3.039</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>famrel5</th>           <td>    0.9855</td> <td>    1.209</td> <td>    0.815</td> <td> 0.416</td> <td>   -1.394</td> <td>    3.365</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>health2</th>           <td>   -0.6146</td> <td>    0.674</td> <td>   -0.911</td> <td> 0.363</td> <td>   -1.942</td> <td>    0.713</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>health3</th>           <td>   -1.5300</td> <td>    0.585</td> <td>   -2.613</td> <td> 0.009</td> <td>   -2.682</td> <td>   -0.378</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>health4</th>           <td>   -1.0136</td> <td>    0.626</td> <td>   -1.620</td> <td> 0.106</td> <td>   -2.245</td> <td>    0.218</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>health5</th>           <td>   -1.2960</td> <td>    0.547</td> <td>   -2.369</td> <td> 0.018</td> <td>   -2.373</td> <td>   -0.219</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 2.512</td> <th>  Durbin-Watson:     </th> <td>   2.125</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.285</td> <th>  Jarque-Bera (JB):  </th> <td>   2.274</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.111</td> <th>  Prob(JB):          </th> <td>   0.321</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.678</td> <th>  Cond. No.          </th> <td>    683.</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                     G3   R-squared:                       0.394\n",
              "Model:                            OLS   Adj. R-squared:                  0.253\n",
              "Method:                 Least Squares   F-statistic:                     2.803\n",
              "Date:                Sat, 11 May 2019   Prob (F-statistic):           1.42e-09\n",
              "Time:                        16:54:25   Log-Likelihood:                -835.03\n",
              "No. Observations:                 357   AIC:                             1806.\n",
              "Df Residuals:                     289   BIC:                             2070.\n",
              "Df Model:                          67                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "=====================================================================================\n",
              "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
              "-------------------------------------------------------------------------------------\n",
              "const                16.3146      4.487      3.636      0.000       7.484      25.145\n",
              "age                  -0.1354      0.164     -0.825      0.410      -0.458       0.188\n",
              "failures             -1.0340      0.281     -3.675      0.000      -1.588      -0.480\n",
              "absences             -0.0550      0.022     -2.540      0.012      -0.098      -0.012\n",
              "school_MS            -0.4731      0.597     -0.792      0.429      -1.649       0.703\n",
              "sex_M                 0.5044      0.375      1.345      0.180      -0.234       1.243\n",
              "address_U             0.4939      0.442      1.116      0.265      -0.377       1.365\n",
              "famsize_LE3           0.4288      0.365      1.175      0.241      -0.290       1.147\n",
              "Pstatus_T            -0.0399      0.545     -0.073      0.942      -1.112       1.032\n",
              "Mjob_health           1.0660      0.851      1.252      0.212      -0.610       2.742\n",
              "Mjob_other           -0.4245      0.558     -0.761      0.447      -1.523       0.674\n",
              "Mjob_services         0.7885      0.625      1.262      0.208      -0.442       2.019\n",
              "Mjob_teacher         -0.6375      0.800     -0.796      0.426      -2.213       0.938\n",
              "Fjob_health          -0.7941      1.067     -0.744      0.457      -2.894       1.306\n",
              "Fjob_other           -0.3607      0.786     -0.459      0.647      -1.909       1.187\n",
              "Fjob_services        -0.5434      0.812     -0.669      0.504      -2.141       1.055\n",
              "Fjob_teacher          1.2324      1.019      1.209      0.228      -0.774       3.238\n",
              "reason_home           0.4104      0.421      0.974      0.331      -0.419       1.240\n",
              "reason_other         -0.0229      0.591     -0.039      0.969      -1.186       1.141\n",
              "reason_reputation     0.2547      0.432      0.590      0.555      -0.595       1.104\n",
              "guardian_mother      -0.0041      0.401     -0.010      0.992      -0.793       0.785\n",
              "guardian_other        0.6634      0.773      0.858      0.392      -0.859       2.186\n",
              "schoolsup_yes        -2.1368      0.488     -4.382      0.000      -3.097      -1.177\n",
              "famsup_yes           -0.7020      0.353     -1.990      0.048      -1.396      -0.008\n",
              "paid_yes             -0.2848      0.359     -0.794      0.428      -0.991       0.421\n",
              "activities_yes       -0.0669      0.339     -0.198      0.844      -0.734       0.600\n",
              "nursery_yes          -0.2617      0.420     -0.623      0.534      -1.089       0.565\n",
              "higher_yes            0.0758      0.934      0.081      0.935      -1.763       1.914\n",
              "internet_yes          0.6104      0.461      1.325      0.186      -0.296       1.517\n",
              "romantic_yes         -0.0120      0.365     -0.033      0.974      -0.730       0.706\n",
              "Medu1                -1.8515      1.795     -1.031      0.303      -5.385       1.682\n",
              "Medu2                -1.5399      1.800     -0.856      0.393      -5.082       2.002\n",
              "Medu3                -1.3645      1.822     -0.749      0.455      -4.951       2.222\n",
              "Medu4                -1.2090      1.870     -0.646      0.518      -4.890       2.472\n",
              "traveltime2          -0.1872      0.383     -0.489      0.625      -0.941       0.566\n",
              "traveltime3           0.7669      0.760      1.009      0.314      -0.730       2.264\n",
              "traveltime4          -0.3450      1.301     -0.265      0.791      -2.906       2.216\n",
              "studytime2           -0.0317      0.417     -0.076      0.939      -0.853       0.790\n",
              "studytime3            1.1585      0.576      2.011      0.045       0.025       2.292\n",
              "studytime4            1.3758      0.752      1.830      0.068      -0.104       2.855\n",
              "freetime2             0.7389      0.857      0.862      0.389      -0.948       2.426\n",
              "freetime3             0.1529      0.826      0.185      0.853      -1.473       1.779\n",
              "freetime4             0.1800      0.855      0.211      0.833      -1.503       1.863\n",
              "freetime5             1.2792      0.968      1.322      0.187      -0.625       3.184\n",
              "goout2                0.4406      0.773      0.570      0.569      -1.081       1.962\n",
              "goout3               -0.3843      0.772     -0.498      0.619      -1.903       1.134\n",
              "goout4               -0.8504      0.813     -1.046      0.297      -2.451       0.750\n",
              "goout5               -1.2672      0.882     -1.436      0.152      -3.004       0.469\n",
              "Dalc2                -0.1075      0.494     -0.217      0.828      -1.080       0.865\n",
              "Dalc3                 0.0492      0.763      0.065      0.949      -1.452       1.551\n",
              "Dalc4                -0.9420      1.150     -0.819      0.413      -3.206       1.322\n",
              "Dalc5                -0.9964      1.348     -0.739      0.460      -3.649       1.656\n",
              "Walc2                -0.5637      0.466     -1.210      0.227      -1.480       0.353\n",
              "Walc3                -0.2894      0.509     -0.569      0.570      -1.291       0.712\n",
              "Walc4                -0.9857      0.654     -1.506      0.133      -2.274       0.302\n",
              "Walc5                 0.7030      1.040      0.676      0.500      -1.345       2.751\n",
              "Fedu1                -0.5798      2.143     -0.271      0.787      -4.798       3.638\n",
              "Fedu2                -0.2362      2.142     -0.110      0.912      -4.452       3.980\n",
              "Fedu3                -0.4048      2.149     -0.188      0.851      -4.634       3.824\n",
              "Fedu4                 0.1427      2.185      0.065      0.948      -4.158       4.443\n",
              "famrel2               1.4468      1.427      1.014      0.312      -1.362       4.256\n",
              "famrel3               0.5621      1.233      0.456      0.649      -1.865       2.989\n",
              "famrel4               0.6923      1.193      0.581      0.562      -1.655       3.039\n",
              "famrel5               0.9855      1.209      0.815      0.416      -1.394       3.365\n",
              "health2              -0.6146      0.674     -0.911      0.363      -1.942       0.713\n",
              "health3              -1.5300      0.585     -2.613      0.009      -2.682      -0.378\n",
              "health4              -1.0136      0.626     -1.620      0.106      -2.245       0.218\n",
              "health5              -1.2960      0.547     -2.369      0.018      -2.373      -0.219\n",
              "==============================================================================\n",
              "Omnibus:                        2.512   Durbin-Watson:                   2.125\n",
              "Prob(Omnibus):                  0.285   Jarque-Bera (JB):                2.274\n",
              "Skew:                           0.111   Prob(JB):                        0.321\n",
              "Kurtosis:                       2.678   Cond. No.                         683.\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-e03_SC0b6U",
        "colab_type": "code",
        "outputId": "fb0a6d19-71b9-4196-a013-576d8cc12380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        }
      },
      "source": [
        "\n",
        "x = df4[['failures','absences','schoolsup_yes','famsup_yes','studytime3','health3','health5']]\n",
        "y = df4[\"G3\"]\n",
        "\n",
        "\n",
        "X1=sm.add_constant(x)                                                \n",
        "model = sm.OLS(y,X1).fit()          \n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
            "  return ptp(axis=axis, out=out, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>           <td>G3</td>        <th>  R-squared:         </th> <td>   0.193</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.177</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.95</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 11 May 2019</td> <th>  Prob (F-statistic):</th> <td>1.13e-13</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>17:00:41</td>     <th>  Log-Likelihood:    </th> <td> -886.04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   357</td>      <th>  AIC:               </th> <td>   1788.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   349</td>      <th>  BIC:               </th> <td>   1819.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>         <td>   13.0288</td> <td>    0.352</td> <td>   37.026</td> <td> 0.000</td> <td>   12.337</td> <td>   13.721</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>failures</th>      <td>   -1.1888</td> <td>    0.236</td> <td>   -5.041</td> <td> 0.000</td> <td>   -1.653</td> <td>   -0.725</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>absences</th>      <td>   -0.0660</td> <td>    0.019</td> <td>   -3.436</td> <td> 0.001</td> <td>   -0.104</td> <td>   -0.028</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>schoolsup_yes</th> <td>   -2.0684</td> <td>    0.452</td> <td>   -4.579</td> <td> 0.000</td> <td>   -2.957</td> <td>   -1.180</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>famsup_yes</th>    <td>   -0.3938</td> <td>    0.321</td> <td>   -1.225</td> <td> 0.221</td> <td>   -1.026</td> <td>    0.238</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>studytime3</th>    <td>    0.9248</td> <td>    0.421</td> <td>    2.197</td> <td> 0.029</td> <td>    0.097</td> <td>    1.753</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>health3</th>       <td>   -0.8707</td> <td>    0.407</td> <td>   -2.138</td> <td> 0.033</td> <td>   -1.672</td> <td>   -0.070</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>health5</th>       <td>   -0.4937</td> <td>    0.357</td> <td>   -1.384</td> <td> 0.167</td> <td>   -1.195</td> <td>    0.208</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 2.398</td> <th>  Durbin-Watson:     </th> <td>   1.998</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.301</td> <th>  Jarque-Bera (JB):  </th> <td>   2.427</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.163</td> <th>  Prob(JB):          </th> <td>   0.297</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.763</td> <th>  Cond. No.          </th> <td>    35.7</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                     G3   R-squared:                       0.193\n",
              "Model:                            OLS   Adj. R-squared:                  0.177\n",
              "Method:                 Least Squares   F-statistic:                     11.95\n",
              "Date:                Sat, 11 May 2019   Prob (F-statistic):           1.13e-13\n",
              "Time:                        17:00:41   Log-Likelihood:                -886.04\n",
              "No. Observations:                 357   AIC:                             1788.\n",
              "Df Residuals:                     349   BIC:                             1819.\n",
              "Df Model:                           7                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "=================================================================================\n",
              "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
              "---------------------------------------------------------------------------------\n",
              "const            13.0288      0.352     37.026      0.000      12.337      13.721\n",
              "failures         -1.1888      0.236     -5.041      0.000      -1.653      -0.725\n",
              "absences         -0.0660      0.019     -3.436      0.001      -0.104      -0.028\n",
              "schoolsup_yes    -2.0684      0.452     -4.579      0.000      -2.957      -1.180\n",
              "famsup_yes       -0.3938      0.321     -1.225      0.221      -1.026       0.238\n",
              "studytime3        0.9248      0.421      2.197      0.029       0.097       1.753\n",
              "health3          -0.8707      0.407     -2.138      0.033      -1.672      -0.070\n",
              "health5          -0.4937      0.357     -1.384      0.167      -1.195       0.208\n",
              "==============================================================================\n",
              "Omnibus:                        2.398   Durbin-Watson:                   1.998\n",
              "Prob(Omnibus):                  0.301   Jarque-Bera (JB):                2.427\n",
              "Skew:                           0.163   Prob(JB):                        0.297\n",
              "Kurtosis:                       2.763   Cond. No.                         35.7\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5MyK3Uk10XS",
        "colab_type": "code",
        "outputId": "11d91d11-eb0a-4b59-9e55-11d58feeb4be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        }
      },
      "source": [
        "\n",
        "x = df4[['failures','absences','schoolsup_yes','studytime3','health3']]\n",
        "y = df4[\"G3\"]\n",
        "\n",
        "\n",
        "X1=sm.add_constant(x)                                                \n",
        "model = sm.OLS(y,X1).fit()          \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
            "  return ptp(axis=axis, out=out, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>           <td>G3</td>        <th>  R-squared:         </th> <td>   0.185</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.174</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.95</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 11 May 2019</td> <th>  Prob (F-statistic):</th> <td>3.61e-14</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>17:01:27</td>     <th>  Log-Likelihood:    </th> <td> -887.84</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   357</td>      <th>  AIC:               </th> <td>   1788.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   351</td>      <th>  BIC:               </th> <td>   1811.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>         <td>   12.5447</td> <td>    0.240</td> <td>   52.349</td> <td> 0.000</td> <td>   12.073</td> <td>   13.016</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>failures</th>      <td>   -1.1894</td> <td>    0.235</td> <td>   -5.057</td> <td> 0.000</td> <td>   -1.652</td> <td>   -0.727</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>absences</th>      <td>   -0.0663</td> <td>    0.019</td> <td>   -3.445</td> <td> 0.001</td> <td>   -0.104</td> <td>   -0.028</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>schoolsup_yes</th> <td>   -2.0798</td> <td>    0.448</td> <td>   -4.638</td> <td> 0.000</td> <td>   -2.962</td> <td>   -1.198</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>studytime3</th>    <td>    0.9476</td> <td>    0.421</td> <td>    2.253</td> <td> 0.025</td> <td>    0.120</td> <td>    1.775</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>health3</th>       <td>   -0.6201</td> <td>    0.369</td> <td>   -1.680</td> <td> 0.094</td> <td>   -1.346</td> <td>    0.106</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 2.221</td> <th>  Durbin-Watson:     </th> <td>   2.031</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.329</td> <th>  Jarque-Bera (JB):  </th> <td>   2.303</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.176</td> <th>  Prob(JB):          </th> <td>   0.316</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.824</td> <th>  Cond. No.          </th> <td>    30.9</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                     G3   R-squared:                       0.185\n",
              "Model:                            OLS   Adj. R-squared:                  0.174\n",
              "Method:                 Least Squares   F-statistic:                     15.95\n",
              "Date:                Sat, 11 May 2019   Prob (F-statistic):           3.61e-14\n",
              "Time:                        17:01:27   Log-Likelihood:                -887.84\n",
              "No. Observations:                 357   AIC:                             1788.\n",
              "Df Residuals:                     351   BIC:                             1811.\n",
              "Df Model:                           5                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "=================================================================================\n",
              "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
              "---------------------------------------------------------------------------------\n",
              "const            12.5447      0.240     52.349      0.000      12.073      13.016\n",
              "failures         -1.1894      0.235     -5.057      0.000      -1.652      -0.727\n",
              "absences         -0.0663      0.019     -3.445      0.001      -0.104      -0.028\n",
              "schoolsup_yes    -2.0798      0.448     -4.638      0.000      -2.962      -1.198\n",
              "studytime3        0.9476      0.421      2.253      0.025       0.120       1.775\n",
              "health3          -0.6201      0.369     -1.680      0.094      -1.346       0.106\n",
              "==============================================================================\n",
              "Omnibus:                        2.221   Durbin-Watson:                   2.031\n",
              "Prob(Omnibus):                  0.329   Jarque-Bera (JB):                2.303\n",
              "Skew:                           0.176   Prob(JB):                        0.316\n",
              "Kurtosis:                       2.824   Cond. No.                         30.9\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tQE9zM61_GW",
        "colab_type": "code",
        "outputId": "1070d597-8cbf-449f-e2a9-30ada20d4915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "x = df4[['failures','absences','schoolsup_yes','studytime3']]\n",
        "y = df4[\"G3\"]\n",
        "\n",
        "\n",
        "X1=sm.add_constant(x)                                                \n",
        "model = sm.OLS(y,X1).fit()          \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
            "  return ptp(axis=axis, out=out, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>           <td>G3</td>        <th>  R-squared:         </th> <td>   0.179</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.169</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   19.14</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 11 May 2019</td> <th>  Prob (F-statistic):</th> <td>2.96e-14</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>17:01:56</td>     <th>  Log-Likelihood:    </th> <td> -889.27</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   357</td>      <th>  AIC:               </th> <td>   1789.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   352</td>      <th>  BIC:               </th> <td>   1808.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>         <td>   12.4123</td> <td>    0.227</td> <td>   54.707</td> <td> 0.000</td> <td>   11.966</td> <td>   12.858</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>failures</th>      <td>   -1.2194</td> <td>    0.235</td> <td>   -5.186</td> <td> 0.000</td> <td>   -1.682</td> <td>   -0.757</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>absences</th>      <td>   -0.0663</td> <td>    0.019</td> <td>   -3.435</td> <td> 0.001</td> <td>   -0.104</td> <td>   -0.028</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>schoolsup_yes</th> <td>   -2.0701</td> <td>    0.450</td> <td>   -4.605</td> <td> 0.000</td> <td>   -2.954</td> <td>   -1.186</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>studytime3</th>    <td>    0.9163</td> <td>    0.421</td> <td>    2.175</td> <td> 0.030</td> <td>    0.088</td> <td>    1.745</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 2.572</td> <th>  Durbin-Watson:     </th> <td>   2.038</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.276</td> <th>  Jarque-Bera (JB):  </th> <td>   2.618</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.177</td> <th>  Prob(JB):          </th> <td>   0.270</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.776</td> <th>  Cond. No.          </th> <td>    30.8</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                     G3   R-squared:                       0.179\n",
              "Model:                            OLS   Adj. R-squared:                  0.169\n",
              "Method:                 Least Squares   F-statistic:                     19.14\n",
              "Date:                Sat, 11 May 2019   Prob (F-statistic):           2.96e-14\n",
              "Time:                        17:01:56   Log-Likelihood:                -889.27\n",
              "No. Observations:                 357   AIC:                             1789.\n",
              "Df Residuals:                     352   BIC:                             1808.\n",
              "Df Model:                           4                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "=================================================================================\n",
              "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
              "---------------------------------------------------------------------------------\n",
              "const            12.4123      0.227     54.707      0.000      11.966      12.858\n",
              "failures         -1.2194      0.235     -5.186      0.000      -1.682      -0.757\n",
              "absences         -0.0663      0.019     -3.435      0.001      -0.104      -0.028\n",
              "schoolsup_yes    -2.0701      0.450     -4.605      0.000      -2.954      -1.186\n",
              "studytime3        0.9163      0.421      2.175      0.030       0.088       1.745\n",
              "==============================================================================\n",
              "Omnibus:                        2.572   Durbin-Watson:                   2.038\n",
              "Prob(Omnibus):                  0.276   Jarque-Bera (JB):                2.618\n",
              "Skew:                           0.177   Prob(JB):                        0.270\n",
              "Kurtosis:                       2.776   Cond. No.                         30.8\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izr9jeO492W9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Regressão linear múltipla com a presença das variáveis explicativas (G1,G2)\n",
        "\n",
        "df1 = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "dummy=pd.get_dummies(df1['Medu'],drop_first=True)\n",
        "dummy.columns=['Medu1','Medu2','Medu3','Medu4']\n",
        "\n",
        "dummy2=pd.get_dummies(df1['traveltime'],drop_first=True)\n",
        "dummy2.columns=['traveltime2','traveltime3','traveltime4']\n",
        "\n",
        "dummy3=pd.get_dummies(df1['studytime'],drop_first=True)\n",
        "dummy3.columns=['studytime2','studytime3','studytime4']\n",
        "\n",
        "dummy4=pd.get_dummies(df1['freetime'],drop_first=True)\n",
        "dummy4.columns=['freetime2','freetime3','freetime4','freetime5']\n",
        "\n",
        "dummy5=pd.get_dummies(df1['goout'],drop_first=True)\n",
        "dummy5.columns=['goout2','goout3','goout4','goout5']\n",
        "\n",
        "dummy6=pd.get_dummies(df1['Dalc'],drop_first=True)\n",
        "dummy6.columns=['Dalc2','Dalc3','Dalc4','Dalc5']\n",
        "\n",
        "dummy7=pd.get_dummies(df1['Walc'],drop_first=True)\n",
        "dummy7.columns=['Walc2','Walc3','Walc4','Walc5']\n",
        "\n",
        "dummy8=pd.get_dummies(df1['Fedu'],drop_first=True)\n",
        "dummy8.columns=['Fedu1','Fedu2','Fedu3','Fedu4']\n",
        "\n",
        "dummy9=pd.get_dummies(df1['famrel'],drop_first=True)\n",
        "dummy9.columns=['famrel2','famrel3','famrel4','famrel5']\n",
        "\n",
        "\n",
        "dummy10=pd.get_dummies(df1['health'],drop_first=True)\n",
        "dummy10.columns=['health2','health3','health4','health5']\n",
        "\n",
        "\n",
        "\n",
        "df4=pd.concat([df1,dummy,dummy2,dummy3,dummy4,dummy5,dummy6,dummy7,dummy8,dummy9,dummy10], axis=1)\n",
        "\n",
        "df4 = df4.drop(['Medu','traveltime','studytime','freetime','goout','Dalc','Walc','Fedu','famrel','health'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odt-1Wio97EI",
        "colab_type": "code",
        "outputId": "6d3efdee-3978-432a-e7ff-40b50ab08f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1962
        }
      },
      "source": [
        "\n",
        "x = df4.drop(\"G3\",axis=1)\n",
        "y = df4[\"G3\"]\n",
        "X1=sm.add_constant(x)                                                \n",
        "model = sm.OLS(y,X1).fit()          \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
            "  return ptp(axis=axis, out=out, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>           <td>G3</td>        <th>  R-squared:         </th> <td>   0.948</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.935</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   75.79</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 11 May 2019</td> <th>  Prob (F-statistic):</th> <td>1.52e-149</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>17:03:26</td>     <th>  Log-Likelihood:    </th> <td> -396.74</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   357</td>      <th>  AIC:               </th> <td>   933.5</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   287</td>      <th>  BIC:               </th> <td>   1205.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    69</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>             <td>   -0.7730</td> <td>    1.368</td> <td>   -0.565</td> <td> 0.573</td> <td>   -3.466</td> <td>    1.920</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>age</th>               <td>    0.0539</td> <td>    0.049</td> <td>    1.098</td> <td> 0.273</td> <td>   -0.043</td> <td>    0.151</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>failures</th>          <td>    0.0223</td> <td>    0.086</td> <td>    0.261</td> <td> 0.794</td> <td>   -0.146</td> <td>    0.191</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>absences</th>          <td>   -0.0100</td> <td>    0.007</td> <td>   -1.532</td> <td> 0.127</td> <td>   -0.023</td> <td>    0.003</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>G1</th>                <td>    0.0967</td> <td>    0.037</td> <td>    2.635</td> <td> 0.009</td> <td>    0.024</td> <td>    0.169</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>G2</th>                <td>    0.8851</td> <td>    0.038</td> <td>   23.430</td> <td> 0.000</td> <td>    0.811</td> <td>    0.959</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>school_MS</th>         <td>   -0.0666</td> <td>    0.176</td> <td>   -0.379</td> <td> 0.705</td> <td>   -0.413</td> <td>    0.279</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>sex_M</th>             <td>   -0.0555</td> <td>    0.111</td> <td>   -0.501</td> <td> 0.617</td> <td>   -0.274</td> <td>    0.163</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>address_U</th>         <td>    0.1718</td> <td>    0.130</td> <td>    1.320</td> <td> 0.188</td> <td>   -0.084</td> <td>    0.428</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>famsize_LE3</th>       <td>   -0.0779</td> <td>    0.108</td> <td>   -0.723</td> <td> 0.470</td> <td>   -0.290</td> <td>    0.134</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Pstatus_T</th>         <td>   -0.1468</td> <td>    0.160</td> <td>   -0.916</td> <td> 0.361</td> <td>   -0.462</td> <td>    0.169</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Mjob_health</th>       <td>    0.2308</td> <td>    0.251</td> <td>    0.921</td> <td> 0.358</td> <td>   -0.263</td> <td>    0.724</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Mjob_other</th>        <td>   -0.1708</td> <td>    0.165</td> <td>   -1.034</td> <td> 0.302</td> <td>   -0.496</td> <td>    0.154</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Mjob_services</th>     <td>    0.0456</td> <td>    0.184</td> <td>    0.247</td> <td> 0.805</td> <td>   -0.317</td> <td>    0.408</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Mjob_teacher</th>      <td>    0.2137</td> <td>    0.236</td> <td>    0.905</td> <td> 0.366</td> <td>   -0.251</td> <td>    0.678</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fjob_health</th>       <td>    0.2230</td> <td>    0.314</td> <td>    0.709</td> <td> 0.479</td> <td>   -0.396</td> <td>    0.842</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fjob_other</th>        <td>    0.3530</td> <td>    0.232</td> <td>    1.524</td> <td> 0.129</td> <td>   -0.103</td> <td>    0.809</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fjob_services</th>     <td>    0.2264</td> <td>    0.239</td> <td>    0.947</td> <td> 0.345</td> <td>   -0.244</td> <td>    0.697</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fjob_teacher</th>      <td>    0.3356</td> <td>    0.300</td> <td>    1.118</td> <td> 0.265</td> <td>   -0.255</td> <td>    0.927</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>reason_home</th>       <td>    0.1953</td> <td>    0.124</td> <td>    1.572</td> <td> 0.117</td> <td>   -0.049</td> <td>    0.440</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>reason_other</th>      <td>    0.0312</td> <td>    0.174</td> <td>    0.179</td> <td> 0.858</td> <td>   -0.312</td> <td>    0.374</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>reason_reputation</th> <td>    0.1310</td> <td>    0.128</td> <td>    1.026</td> <td> 0.306</td> <td>   -0.120</td> <td>    0.382</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>guardian_mother</th>   <td>    0.0012</td> <td>    0.118</td> <td>    0.010</td> <td> 0.992</td> <td>   -0.231</td> <td>    0.233</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>guardian_other</th>    <td>   -0.3369</td> <td>    0.228</td> <td>   -1.477</td> <td> 0.141</td> <td>   -0.786</td> <td>    0.112</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>schoolsup_yes</th>     <td>   -0.1643</td> <td>    0.148</td> <td>   -1.110</td> <td> 0.268</td> <td>   -0.455</td> <td>    0.127</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>famsup_yes</th>        <td>    0.1008</td> <td>    0.105</td> <td>    0.959</td> <td> 0.338</td> <td>   -0.106</td> <td>    0.308</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>paid_yes</th>          <td>   -0.1273</td> <td>    0.106</td> <td>   -1.206</td> <td> 0.229</td> <td>   -0.335</td> <td>    0.081</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>activities_yes</th>    <td>   -0.0440</td> <td>    0.100</td> <td>   -0.442</td> <td> 0.659</td> <td>   -0.240</td> <td>    0.152</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>nursery_yes</th>       <td>   -0.1998</td> <td>    0.124</td> <td>   -1.617</td> <td> 0.107</td> <td>   -0.443</td> <td>    0.043</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>higher_yes</th>        <td>   -0.0383</td> <td>    0.275</td> <td>   -0.139</td> <td> 0.889</td> <td>   -0.579</td> <td>    0.503</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>internet_yes</th>      <td>    0.0317</td> <td>    0.136</td> <td>    0.232</td> <td> 0.816</td> <td>   -0.237</td> <td>    0.300</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>romantic_yes</th>      <td>    0.0474</td> <td>    0.108</td> <td>    0.441</td> <td> 0.659</td> <td>   -0.164</td> <td>    0.259</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Medu1</th>             <td>   -0.1199</td> <td>    0.529</td> <td>   -0.227</td> <td> 0.821</td> <td>   -1.161</td> <td>    0.921</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Medu2</th>             <td>   -0.1343</td> <td>    0.530</td> <td>   -0.254</td> <td> 0.800</td> <td>   -1.177</td> <td>    0.908</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Medu3</th>             <td>   -0.2696</td> <td>    0.536</td> <td>   -0.503</td> <td> 0.615</td> <td>   -1.325</td> <td>    0.786</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Medu4</th>             <td>   -0.2538</td> <td>    0.550</td> <td>   -0.461</td> <td> 0.645</td> <td>   -1.337</td> <td>    0.829</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>traveltime2</th>       <td>   -0.0948</td> <td>    0.113</td> <td>   -0.841</td> <td> 0.401</td> <td>   -0.316</td> <td>    0.127</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>traveltime3</th>       <td>   -0.1113</td> <td>    0.224</td> <td>   -0.496</td> <td> 0.620</td> <td>   -0.553</td> <td>    0.330</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>traveltime4</th>       <td>    0.8160</td> <td>    0.383</td> <td>    2.128</td> <td> 0.034</td> <td>    0.061</td> <td>    1.571</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>studytime2</th>        <td>   -0.0004</td> <td>    0.123</td> <td>   -0.004</td> <td> 0.997</td> <td>   -0.243</td> <td>    0.242</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>studytime3</th>        <td>   -0.0008</td> <td>    0.172</td> <td>   -0.005</td> <td> 0.996</td> <td>   -0.339</td> <td>    0.337</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>studytime4</th>        <td>    0.1324</td> <td>    0.223</td> <td>    0.593</td> <td> 0.554</td> <td>   -0.307</td> <td>    0.572</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>freetime2</th>         <td>    0.1502</td> <td>    0.254</td> <td>    0.591</td> <td> 0.555</td> <td>   -0.350</td> <td>    0.650</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>freetime3</th>         <td>    0.1667</td> <td>    0.243</td> <td>    0.685</td> <td> 0.494</td> <td>   -0.313</td> <td>    0.646</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>freetime4</th>         <td>    0.0874</td> <td>    0.252</td> <td>    0.347</td> <td> 0.729</td> <td>   -0.409</td> <td>    0.584</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>freetime5</th>         <td>    0.1441</td> <td>    0.289</td> <td>    0.499</td> <td> 0.618</td> <td>   -0.424</td> <td>    0.713</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>goout2</th>            <td>   -0.2523</td> <td>    0.229</td> <td>   -1.103</td> <td> 0.271</td> <td>   -0.703</td> <td>    0.198</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>goout3</th>            <td>   -0.3036</td> <td>    0.228</td> <td>   -1.334</td> <td> 0.183</td> <td>   -0.751</td> <td>    0.144</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>goout4</th>            <td>   -0.4737</td> <td>    0.240</td> <td>   -1.977</td> <td> 0.049</td> <td>   -0.945</td> <td>   -0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>goout5</th>            <td>   -0.5608</td> <td>    0.261</td> <td>   -2.153</td> <td> 0.032</td> <td>   -1.074</td> <td>   -0.048</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Dalc2</th>             <td>    0.0279</td> <td>    0.145</td> <td>    0.192</td> <td> 0.848</td> <td>   -0.258</td> <td>    0.314</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Dalc3</th>             <td>    0.3019</td> <td>    0.225</td> <td>    1.344</td> <td> 0.180</td> <td>   -0.140</td> <td>    0.744</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Dalc4</th>             <td>    0.0670</td> <td>    0.339</td> <td>    0.198</td> <td> 0.843</td> <td>   -0.600</td> <td>    0.734</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Dalc5</th>             <td>   -0.5081</td> <td>    0.397</td> <td>   -1.281</td> <td> 0.201</td> <td>   -1.289</td> <td>    0.273</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Walc2</th>             <td>   -0.1302</td> <td>    0.138</td> <td>   -0.946</td> <td> 0.345</td> <td>   -0.401</td> <td>    0.141</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Walc3</th>             <td>   -0.1424</td> <td>    0.150</td> <td>   -0.951</td> <td> 0.342</td> <td>   -0.437</td> <td>    0.152</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Walc4</th>             <td>   -0.1471</td> <td>    0.193</td> <td>   -0.762</td> <td> 0.447</td> <td>   -0.527</td> <td>    0.233</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Walc5</th>             <td>    0.1168</td> <td>    0.307</td> <td>    0.381</td> <td> 0.704</td> <td>   -0.487</td> <td>    0.721</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fedu1</th>             <td>    0.1939</td> <td>    0.631</td> <td>    0.308</td> <td> 0.759</td> <td>   -1.047</td> <td>    1.435</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fedu2</th>             <td>    0.1597</td> <td>    0.631</td> <td>    0.253</td> <td> 0.800</td> <td>   -1.082</td> <td>    1.401</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fedu3</th>             <td>    0.1227</td> <td>    0.632</td> <td>    0.194</td> <td> 0.846</td> <td>   -1.122</td> <td>    1.367</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fedu4</th>             <td>    0.1349</td> <td>    0.643</td> <td>    0.210</td> <td> 0.834</td> <td>   -1.131</td> <td>    1.401</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>famrel2</th>           <td>    0.5019</td> <td>    0.422</td> <td>    1.191</td> <td> 0.235</td> <td>   -0.328</td> <td>    1.332</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>famrel3</th>           <td>    0.6168</td> <td>    0.363</td> <td>    1.697</td> <td> 0.091</td> <td>   -0.098</td> <td>    1.332</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>famrel4</th>           <td>    0.5429</td> <td>    0.352</td> <td>    1.543</td> <td> 0.124</td> <td>   -0.150</td> <td>    1.235</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>famrel5</th>           <td>    0.9181</td> <td>    0.357</td> <td>    2.574</td> <td> 0.011</td> <td>    0.216</td> <td>    1.620</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>health2</th>           <td>    0.1549</td> <td>    0.199</td> <td>    0.778</td> <td> 0.437</td> <td>   -0.237</td> <td>    0.547</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>health3</th>           <td>   -0.1255</td> <td>    0.174</td> <td>   -0.720</td> <td> 0.472</td> <td>   -0.469</td> <td>    0.218</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>health4</th>           <td>   -0.0277</td> <td>    0.185</td> <td>   -0.150</td> <td> 0.881</td> <td>   -0.391</td> <td>    0.336</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>health5</th>           <td>   -0.2499</td> <td>    0.162</td> <td>   -1.543</td> <td> 0.124</td> <td>   -0.569</td> <td>    0.069</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 2.303</td> <th>  Durbin-Watson:     </th> <td>   1.978</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.316</td> <th>  Jarque-Bera (JB):  </th> <td>   2.278</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.054</td> <th>  Prob(JB):          </th> <td>   0.320</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 3.376</td> <th>  Cond. No.          </th> <td>    921.</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                     G3   R-squared:                       0.948\n",
              "Model:                            OLS   Adj. R-squared:                  0.935\n",
              "Method:                 Least Squares   F-statistic:                     75.79\n",
              "Date:                Sat, 11 May 2019   Prob (F-statistic):          1.52e-149\n",
              "Time:                        17:03:26   Log-Likelihood:                -396.74\n",
              "No. Observations:                 357   AIC:                             933.5\n",
              "Df Residuals:                     287   BIC:                             1205.\n",
              "Df Model:                          69                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "=====================================================================================\n",
              "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
              "-------------------------------------------------------------------------------------\n",
              "const                -0.7730      1.368     -0.565      0.573      -3.466       1.920\n",
              "age                   0.0539      0.049      1.098      0.273      -0.043       0.151\n",
              "failures              0.0223      0.086      0.261      0.794      -0.146       0.191\n",
              "absences             -0.0100      0.007     -1.532      0.127      -0.023       0.003\n",
              "G1                    0.0967      0.037      2.635      0.009       0.024       0.169\n",
              "G2                    0.8851      0.038     23.430      0.000       0.811       0.959\n",
              "school_MS            -0.0666      0.176     -0.379      0.705      -0.413       0.279\n",
              "sex_M                -0.0555      0.111     -0.501      0.617      -0.274       0.163\n",
              "address_U             0.1718      0.130      1.320      0.188      -0.084       0.428\n",
              "famsize_LE3          -0.0779      0.108     -0.723      0.470      -0.290       0.134\n",
              "Pstatus_T            -0.1468      0.160     -0.916      0.361      -0.462       0.169\n",
              "Mjob_health           0.2308      0.251      0.921      0.358      -0.263       0.724\n",
              "Mjob_other           -0.1708      0.165     -1.034      0.302      -0.496       0.154\n",
              "Mjob_services         0.0456      0.184      0.247      0.805      -0.317       0.408\n",
              "Mjob_teacher          0.2137      0.236      0.905      0.366      -0.251       0.678\n",
              "Fjob_health           0.2230      0.314      0.709      0.479      -0.396       0.842\n",
              "Fjob_other            0.3530      0.232      1.524      0.129      -0.103       0.809\n",
              "Fjob_services         0.2264      0.239      0.947      0.345      -0.244       0.697\n",
              "Fjob_teacher          0.3356      0.300      1.118      0.265      -0.255       0.927\n",
              "reason_home           0.1953      0.124      1.572      0.117      -0.049       0.440\n",
              "reason_other          0.0312      0.174      0.179      0.858      -0.312       0.374\n",
              "reason_reputation     0.1310      0.128      1.026      0.306      -0.120       0.382\n",
              "guardian_mother       0.0012      0.118      0.010      0.992      -0.231       0.233\n",
              "guardian_other       -0.3369      0.228     -1.477      0.141      -0.786       0.112\n",
              "schoolsup_yes        -0.1643      0.148     -1.110      0.268      -0.455       0.127\n",
              "famsup_yes            0.1008      0.105      0.959      0.338      -0.106       0.308\n",
              "paid_yes             -0.1273      0.106     -1.206      0.229      -0.335       0.081\n",
              "activities_yes       -0.0440      0.100     -0.442      0.659      -0.240       0.152\n",
              "nursery_yes          -0.1998      0.124     -1.617      0.107      -0.443       0.043\n",
              "higher_yes           -0.0383      0.275     -0.139      0.889      -0.579       0.503\n",
              "internet_yes          0.0317      0.136      0.232      0.816      -0.237       0.300\n",
              "romantic_yes          0.0474      0.108      0.441      0.659      -0.164       0.259\n",
              "Medu1                -0.1199      0.529     -0.227      0.821      -1.161       0.921\n",
              "Medu2                -0.1343      0.530     -0.254      0.800      -1.177       0.908\n",
              "Medu3                -0.2696      0.536     -0.503      0.615      -1.325       0.786\n",
              "Medu4                -0.2538      0.550     -0.461      0.645      -1.337       0.829\n",
              "traveltime2          -0.0948      0.113     -0.841      0.401      -0.316       0.127\n",
              "traveltime3          -0.1113      0.224     -0.496      0.620      -0.553       0.330\n",
              "traveltime4           0.8160      0.383      2.128      0.034       0.061       1.571\n",
              "studytime2           -0.0004      0.123     -0.004      0.997      -0.243       0.242\n",
              "studytime3           -0.0008      0.172     -0.005      0.996      -0.339       0.337\n",
              "studytime4            0.1324      0.223      0.593      0.554      -0.307       0.572\n",
              "freetime2             0.1502      0.254      0.591      0.555      -0.350       0.650\n",
              "freetime3             0.1667      0.243      0.685      0.494      -0.313       0.646\n",
              "freetime4             0.0874      0.252      0.347      0.729      -0.409       0.584\n",
              "freetime5             0.1441      0.289      0.499      0.618      -0.424       0.713\n",
              "goout2               -0.2523      0.229     -1.103      0.271      -0.703       0.198\n",
              "goout3               -0.3036      0.228     -1.334      0.183      -0.751       0.144\n",
              "goout4               -0.4737      0.240     -1.977      0.049      -0.945      -0.002\n",
              "goout5               -0.5608      0.261     -2.153      0.032      -1.074      -0.048\n",
              "Dalc2                 0.0279      0.145      0.192      0.848      -0.258       0.314\n",
              "Dalc3                 0.3019      0.225      1.344      0.180      -0.140       0.744\n",
              "Dalc4                 0.0670      0.339      0.198      0.843      -0.600       0.734\n",
              "Dalc5                -0.5081      0.397     -1.281      0.201      -1.289       0.273\n",
              "Walc2                -0.1302      0.138     -0.946      0.345      -0.401       0.141\n",
              "Walc3                -0.1424      0.150     -0.951      0.342      -0.437       0.152\n",
              "Walc4                -0.1471      0.193     -0.762      0.447      -0.527       0.233\n",
              "Walc5                 0.1168      0.307      0.381      0.704      -0.487       0.721\n",
              "Fedu1                 0.1939      0.631      0.308      0.759      -1.047       1.435\n",
              "Fedu2                 0.1597      0.631      0.253      0.800      -1.082       1.401\n",
              "Fedu3                 0.1227      0.632      0.194      0.846      -1.122       1.367\n",
              "Fedu4                 0.1349      0.643      0.210      0.834      -1.131       1.401\n",
              "famrel2               0.5019      0.422      1.191      0.235      -0.328       1.332\n",
              "famrel3               0.6168      0.363      1.697      0.091      -0.098       1.332\n",
              "famrel4               0.5429      0.352      1.543      0.124      -0.150       1.235\n",
              "famrel5               0.9181      0.357      2.574      0.011       0.216       1.620\n",
              "health2               0.1549      0.199      0.778      0.437      -0.237       0.547\n",
              "health3              -0.1255      0.174     -0.720      0.472      -0.469       0.218\n",
              "health4              -0.0277      0.185     -0.150      0.881      -0.391       0.336\n",
              "health5              -0.2499      0.162     -1.543      0.124      -0.569       0.069\n",
              "==============================================================================\n",
              "Omnibus:                        2.303   Durbin-Watson:                   1.978\n",
              "Prob(Omnibus):                  0.316   Jarque-Bera (JB):                2.278\n",
              "Skew:                           0.054   Prob(JB):                        0.320\n",
              "Kurtosis:                       3.376   Cond. No.                         921.\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8J4uMyw_OE9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Zis4E9M_PnO",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qlu_odp-oSR",
        "colab_type": "code",
        "outputId": "c29e9568-f5c7-4ab1-e7d1-dbc463435d1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        }
      },
      "source": [
        "\n",
        "x = df4[['G1','G2','traveltime4','goout4','goout5','famrel5']]\n",
        "y = df4[\"G3\"]\n",
        "\n",
        "\n",
        "X1=sm.add_constant(x)                                                \n",
        "model = sm.OLS(y,X1).fit()          \n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
            "  return ptp(axis=axis, out=out, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>           <td>G3</td>        <th>  R-squared:         </th> <td>   0.940</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.939</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   908.1</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 11 May 2019</td> <th>  Prob (F-statistic):</th> <td>5.85e-210</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>17:05:10</td>     <th>  Log-Likelihood:    </th> <td> -423.26</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   357</td>      <th>  AIC:               </th> <td>   860.5</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   350</td>      <th>  BIC:               </th> <td>   887.7</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>       <td>    0.1824</td> <td>    0.172</td> <td>    1.063</td> <td> 0.289</td> <td>   -0.155</td> <td>    0.520</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>G1</th>          <td>    0.1127</td> <td>    0.030</td> <td>    3.711</td> <td> 0.000</td> <td>    0.053</td> <td>    0.172</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>G2</th>          <td>    0.8826</td> <td>    0.031</td> <td>   28.214</td> <td> 0.000</td> <td>    0.821</td> <td>    0.944</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>traveltime4</th> <td>    0.8499</td> <td>    0.317</td> <td>    2.684</td> <td> 0.008</td> <td>    0.227</td> <td>    1.473</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>goout4</th>      <td>   -0.1756</td> <td>    0.106</td> <td>   -1.656</td> <td> 0.099</td> <td>   -0.384</td> <td>    0.033</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>goout5</th>      <td>   -0.2960</td> <td>    0.135</td> <td>   -2.195</td> <td> 0.029</td> <td>   -0.561</td> <td>   -0.031</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>famrel5</th>     <td>    0.3913</td> <td>    0.096</td> <td>    4.092</td> <td> 0.000</td> <td>    0.203</td> <td>    0.579</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 0.817</td> <th>  Durbin-Watson:     </th> <td>   1.925</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.665</td> <th>  Jarque-Bera (JB):  </th> <td>   0.583</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.037</td> <th>  Prob(JB):          </th> <td>   0.747</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 3.184</td> <th>  Cond. No.          </th> <td>    125.</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                     G3   R-squared:                       0.940\n",
              "Model:                            OLS   Adj. R-squared:                  0.939\n",
              "Method:                 Least Squares   F-statistic:                     908.1\n",
              "Date:                Sat, 11 May 2019   Prob (F-statistic):          5.85e-210\n",
              "Time:                        17:05:10   Log-Likelihood:                -423.26\n",
              "No. Observations:                 357   AIC:                             860.5\n",
              "Df Residuals:                     350   BIC:                             887.7\n",
              "Df Model:                           6                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "===============================================================================\n",
              "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
              "-------------------------------------------------------------------------------\n",
              "const           0.1824      0.172      1.063      0.289      -0.155       0.520\n",
              "G1              0.1127      0.030      3.711      0.000       0.053       0.172\n",
              "G2              0.8826      0.031     28.214      0.000       0.821       0.944\n",
              "traveltime4     0.8499      0.317      2.684      0.008       0.227       1.473\n",
              "goout4         -0.1756      0.106     -1.656      0.099      -0.384       0.033\n",
              "goout5         -0.2960      0.135     -2.195      0.029      -0.561      -0.031\n",
              "famrel5         0.3913      0.096      4.092      0.000       0.203       0.579\n",
              "==============================================================================\n",
              "Omnibus:                        0.817   Durbin-Watson:                   1.925\n",
              "Prob(Omnibus):                  0.665   Jarque-Bera (JB):                0.583\n",
              "Skew:                           0.037   Prob(JB):                        0.747\n",
              "Kurtosis:                       3.184   Cond. No.                         125.\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXpJOBGxAmTS",
        "colab_type": "code",
        "outputId": "e94d60e2-bb98-49e6-bfd9-8f58274e535a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        }
      },
      "source": [
        "\n",
        "x = df4[['G1','G2','traveltime4','goout5','famrel5']]\n",
        "y = df4[\"G3\"]\n",
        "\n",
        "\n",
        "X1=sm.add_constant(x)                                                \n",
        "model = sm.OLS(y,X1).fit()          \n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
            "  return ptp(axis=axis, out=out, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>           <td>G3</td>        <th>  R-squared:         </th> <td>   0.939</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.938</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1084.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 11 May 2019</td> <th>  Prob (F-statistic):</th> <td>6.62e-211</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>17:05:11</td>     <th>  Log-Likelihood:    </th> <td> -424.65</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   357</td>      <th>  AIC:               </th> <td>   861.3</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   351</td>      <th>  BIC:               </th> <td>   884.6</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>       <td>    0.1052</td> <td>    0.166</td> <td>    0.635</td> <td> 0.526</td> <td>   -0.220</td> <td>    0.431</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>G1</th>          <td>    0.1118</td> <td>    0.030</td> <td>    3.673</td> <td> 0.000</td> <td>    0.052</td> <td>    0.172</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>G2</th>          <td>    0.8863</td> <td>    0.031</td> <td>   28.337</td> <td> 0.000</td> <td>    0.825</td> <td>    0.948</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>traveltime4</th> <td>    0.8686</td> <td>    0.317</td> <td>    2.738</td> <td> 0.006</td> <td>    0.245</td> <td>    1.493</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>goout5</th>      <td>   -0.2527</td> <td>    0.133</td> <td>   -1.905</td> <td> 0.058</td> <td>   -0.514</td> <td>    0.008</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>famrel5</th>     <td>    0.3962</td> <td>    0.096</td> <td>    4.135</td> <td> 0.000</td> <td>    0.208</td> <td>    0.585</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 0.858</td> <th>  Durbin-Watson:     </th> <td>   1.913</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.651</td> <th>  Jarque-Bera (JB):  </th> <td>   0.622</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.043</td> <th>  Prob(JB):          </th> <td>   0.733</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 3.186</td> <th>  Cond. No.          </th> <td>    125.</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                     G3   R-squared:                       0.939\n",
              "Model:                            OLS   Adj. R-squared:                  0.938\n",
              "Method:                 Least Squares   F-statistic:                     1084.\n",
              "Date:                Sat, 11 May 2019   Prob (F-statistic):          6.62e-211\n",
              "Time:                        17:05:11   Log-Likelihood:                -424.65\n",
              "No. Observations:                 357   AIC:                             861.3\n",
              "Df Residuals:                     351   BIC:                             884.6\n",
              "Df Model:                           5                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "===============================================================================\n",
              "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
              "-------------------------------------------------------------------------------\n",
              "const           0.1052      0.166      0.635      0.526      -0.220       0.431\n",
              "G1              0.1118      0.030      3.673      0.000       0.052       0.172\n",
              "G2              0.8863      0.031     28.337      0.000       0.825       0.948\n",
              "traveltime4     0.8686      0.317      2.738      0.006       0.245       1.493\n",
              "goout5         -0.2527      0.133     -1.905      0.058      -0.514       0.008\n",
              "famrel5         0.3962      0.096      4.135      0.000       0.208       0.585\n",
              "==============================================================================\n",
              "Omnibus:                        0.858   Durbin-Watson:                   1.913\n",
              "Prob(Omnibus):                  0.651   Jarque-Bera (JB):                0.622\n",
              "Skew:                           0.043   Prob(JB):                        0.733\n",
              "Kurtosis:                       3.186   Cond. No.                         125.\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0YlA1NJ9AZi",
        "colab_type": "code",
        "outputId": "798eb424-3089-43bc-83d2-9f77c87a7416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "\n",
        "x = df4[['G1','G2','traveltime4','famrel5']]\n",
        "y = df4[\"G3\"]\n",
        "\n",
        "\n",
        "X1=sm.add_constant(x)                                                \n",
        "model = sm.OLS(y,X1).fit()          \n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
            "  return ptp(axis=axis, out=out, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>           <td>G3</td>        <th>  R-squared:         </th> <td>   0.939</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.938</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1344.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 11 May 2019</td> <th>  Prob (F-statistic):</th> <td>1.03e-211</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>17:05:19</td>     <th>  Log-Likelihood:    </th> <td> -426.49</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   357</td>      <th>  AIC:               </th> <td>   863.0</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   352</td>      <th>  BIC:               </th> <td>   882.4</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>       <td>    0.0558</td> <td>    0.164</td> <td>    0.340</td> <td> 0.734</td> <td>   -0.267</td> <td>    0.379</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>G1</th>          <td>    0.1150</td> <td>    0.030</td> <td>    3.770</td> <td> 0.000</td> <td>    0.055</td> <td>    0.175</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>G2</th>          <td>    0.8851</td> <td>    0.031</td> <td>   28.199</td> <td> 0.000</td> <td>    0.823</td> <td>    0.947</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>traveltime4</th> <td>    0.7222</td> <td>    0.309</td> <td>    2.338</td> <td> 0.020</td> <td>    0.115</td> <td>    1.330</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>famrel5</th>     <td>    0.3893</td> <td>    0.096</td> <td>    4.051</td> <td> 0.000</td> <td>    0.200</td> <td>    0.578</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 1.214</td> <th>  Durbin-Watson:     </th> <td>   1.916</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.545</td> <th>  Jarque-Bera (JB):  </th> <td>   0.994</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.022</td> <th>  Prob(JB):          </th> <td>   0.609</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 3.255</td> <th>  Cond. No.          </th> <td>    121.</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                     G3   R-squared:                       0.939\n",
              "Model:                            OLS   Adj. R-squared:                  0.938\n",
              "Method:                 Least Squares   F-statistic:                     1344.\n",
              "Date:                Sat, 11 May 2019   Prob (F-statistic):          1.03e-211\n",
              "Time:                        17:05:19   Log-Likelihood:                -426.49\n",
              "No. Observations:                 357   AIC:                             863.0\n",
              "Df Residuals:                     352   BIC:                             882.4\n",
              "Df Model:                           4                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "===============================================================================\n",
              "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
              "-------------------------------------------------------------------------------\n",
              "const           0.0558      0.164      0.340      0.734      -0.267       0.379\n",
              "G1              0.1150      0.030      3.770      0.000       0.055       0.175\n",
              "G2              0.8851      0.031     28.199      0.000       0.823       0.947\n",
              "traveltime4     0.7222      0.309      2.338      0.020       0.115       1.330\n",
              "famrel5         0.3893      0.096      4.051      0.000       0.200       0.578\n",
              "==============================================================================\n",
              "Omnibus:                        1.214   Durbin-Watson:                   1.916\n",
              "Prob(Omnibus):                  0.545   Jarque-Bera (JB):                0.994\n",
              "Skew:                           0.022   Prob(JB):                        0.609\n",
              "Kurtosis:                       3.255   Cond. No.                         121.\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}